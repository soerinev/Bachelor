{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5bd183ee-fe9a-4285-be88-9e3daa58b1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement os (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for os\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install os\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "804de36d-a797-4b0c-8109-310a98d68aa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/work'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see directory\n",
    "os. getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b88db6d9-d646-4ac3-89b9-62304a50fa7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing line 10000\n",
      "Processing line 20000\n",
      "Processing line 30000\n",
      "Processing line 40000\n",
      "Processing line 50000\n",
      "Processing line 60000\n",
      "Processing line 70000\n",
      "Processing line 80000\n",
      "Processing line 90000\n",
      "Processing line 100000\n",
      "Processing line 110000\n",
      "Processing line 120000\n",
      "Processing line 130000\n",
      "Processing line 140000\n",
      "Processing line 150000\n",
      "Processing line 160000\n",
      "Processing line 170000\n",
      "Processing line 180000\n",
      "Processing line 190000\n",
      "Processing line 200000\n",
      "Processing line 210000\n",
      "Processing line 220000\n",
      "Processing line 230000\n",
      "Processing line 240000\n",
      "Processing line 250000\n",
      "Processing line 260000\n",
      "Processing line 270000\n",
      "Processing line 280000\n",
      "Processing line 290000\n",
      "Processing line 300000\n",
      "Processing line 310000\n",
      "Processing line 320000\n",
      "Processing line 330000\n",
      "Processing line 340000\n",
      "Processing line 350000\n",
      "Processing line 360000\n",
      "Processing line 370000\n",
      "Processing line 380000\n",
      "Processing line 390000\n",
      "Processing line 400000\n",
      "Processing line 410000\n",
      "Processing line 420000\n",
      "Processing line 430000\n",
      "Processing line 440000\n",
      "Processing line 450000\n",
      "Processing line 460000\n",
      "Processing line 470000\n",
      "Processing line 480000\n",
      "Processing line 490000\n",
      "Processing line 500000\n",
      "Writing file /work/Bachelor/sample_data/split/database_1.txt\n",
      "Processing line 10000\n",
      "Processing line 20000\n",
      "Processing line 30000\n",
      "Processing line 40000\n",
      "Processing line 50000\n",
      "Processing line 60000\n",
      "Processing line 70000\n",
      "Processing line 80000\n",
      "Processing line 90000\n",
      "Processing line 100000\n",
      "Processing line 110000\n",
      "Processing line 120000\n",
      "Processing line 130000\n",
      "Processing line 140000\n",
      "Processing line 150000\n",
      "Processing line 160000\n",
      "Processing line 170000\n",
      "Processing line 180000\n",
      "Processing line 190000\n",
      "Processing line 200000\n",
      "Processing line 210000\n",
      "Processing line 220000\n",
      "Processing line 230000\n",
      "Processing line 240000\n",
      "Processing line 250000\n",
      "Processing line 260000\n",
      "Processing line 270000\n",
      "Processing line 280000\n",
      "Processing line 290000\n",
      "Processing line 300000\n",
      "Processing line 310000\n",
      "Processing line 320000\n",
      "Processing line 330000\n",
      "Processing line 340000\n",
      "Processing line 350000\n",
      "Processing line 360000\n",
      "Processing line 370000\n",
      "Processing line 380000\n",
      "Processing line 390000\n",
      "Processing line 400000\n",
      "Processing line 410000\n",
      "Processing line 420000\n",
      "Processing line 430000\n",
      "Processing line 440000\n",
      "Processing line 450000\n",
      "Processing line 460000\n",
      "Processing line 470000\n",
      "Processing line 480000\n",
      "Processing line 490000\n",
      "Processing line 500000\n",
      "Writing file /work/Bachelor/sample_data/split/database_2.txt\n",
      "Processing line 10000\n",
      "Processing line 20000\n",
      "Processing line 30000\n",
      "Processing line 40000\n",
      "Processing line 50000\n",
      "Processing line 60000\n",
      "Processing line 70000\n",
      "Processing line 80000\n",
      "Processing line 90000\n",
      "Processing line 100000\n",
      "Processing line 110000\n",
      "Processing line 120000\n",
      "Processing line 130000\n",
      "Processing line 140000\n",
      "Processing line 150000\n",
      "Processing line 160000\n",
      "Processing line 170000\n",
      "Processing line 180000\n",
      "Processing line 190000\n",
      "Processing line 200000\n",
      "Processing line 210000\n",
      "Processing line 220000\n",
      "Processing line 230000\n",
      "Processing line 240000\n",
      "Processing line 250000\n",
      "Processing line 260000\n",
      "Processing line 270000\n",
      "Processing line 280000\n",
      "Processing line 290000\n",
      "Processing line 300000\n",
      "Processing line 310000\n",
      "Processing line 320000\n",
      "Processing line 330000\n",
      "Processing line 340000\n",
      "Processing line 350000\n",
      "Processing line 360000\n",
      "Processing line 370000\n",
      "Processing line 380000\n",
      "Processing line 390000\n",
      "Processing line 400000\n",
      "Processing line 410000\n",
      "Processing line 420000\n",
      "Processing line 430000\n",
      "Processing line 440000\n",
      "Processing line 450000\n",
      "Processing line 460000\n",
      "Processing line 470000\n",
      "Processing line 480000\n",
      "Processing line 490000\n",
      "Processing line 500000\n",
      "Writing file /work/Bachelor/sample_data/split/database_3.txt\n",
      "Processing line 10000\n",
      "Processing line 20000\n",
      "Processing line 30000\n",
      "Processing line 40000\n",
      "Processing line 50000\n",
      "Processing line 60000\n",
      "Processing line 70000\n",
      "Processing line 80000\n",
      "Processing line 90000\n",
      "Processing line 100000\n",
      "Processing line 110000\n",
      "Processing line 120000\n",
      "Processing line 130000\n",
      "Processing line 140000\n",
      "Processing line 150000\n",
      "Processing line 160000\n",
      "Processing line 170000\n",
      "Processing line 180000\n",
      "Processing line 190000\n",
      "Processing line 200000\n",
      "Processing line 210000\n",
      "Processing line 220000\n",
      "Processing line 230000\n",
      "Processing line 240000\n",
      "Processing line 250000\n",
      "Processing line 260000\n",
      "Processing line 270000\n",
      "Processing line 280000\n",
      "Processing line 290000\n",
      "Processing line 300000\n",
      "Processing line 310000\n",
      "Processing line 320000\n",
      "Processing line 330000\n",
      "Processing line 340000\n",
      "Processing line 350000\n",
      "Processing line 360000\n",
      "Processing line 370000\n",
      "Processing line 380000\n",
      "Processing line 390000\n",
      "Processing line 400000\n",
      "Processing line 410000\n",
      "Processing line 420000\n",
      "Processing line 430000\n",
      "Processing line 440000\n",
      "Processing line 450000\n",
      "Writing final file /work/Bachelor/sample_data/split/database_4.txt\n"
     ]
    }
   ],
   "source": [
    "# make function that can split database.txt file into smaller txt files\n",
    "def split_file_by_lines(file_path, lines_per_file):\n",
    "    \"\"\"Splits a large text file into smaller files with a specific number of lines each.\"\"\"\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    output_folder = os.path.dirname(file_path)  # Get the directory of the input file\n",
    "    base_filename = os.path.splitext(os.path.basename(file_path))[0]  # Get the base name of the input file (without extension)\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        file_count = 1\n",
    "        current_lines = []\n",
    "        \n",
    "        for line in file:\n",
    "            current_lines.append(line)\n",
    "            \n",
    "            # Print progress for debugging\n",
    "            if len(current_lines) % 10000 == 0:\n",
    "                print(f\"Processing line {len(current_lines)}\")\n",
    "            \n",
    "            # When we've collected enough lines, write them to a new file\n",
    "            if len(current_lines) == lines_per_file:\n",
    "                output_file_path = os.path.join(output_folder, f'{base_filename}_{file_count}.txt')\n",
    "                print(f\"Writing file {output_file_path}\")\n",
    "                with open(output_file_path, 'w') as new_file:\n",
    "                    new_file.writelines(current_lines)\n",
    "                file_count += 1\n",
    "                current_lines = []  # Reset for the next file\n",
    "        \n",
    "        # Write any remaining lines to a final file\n",
    "        if current_lines:\n",
    "            output_file_path = os.path.join(output_folder, f'{base_filename}_{file_count}.txt')\n",
    "            print(f\"Writing final file {output_file_path}\")\n",
    "            with open(output_file_path, 'w') as new_file:\n",
    "                new_file.writelines(current_lines)\n",
    "\n",
    "# use function to split database.txt into smaller txt files\n",
    "split_file_by_lines('/work/Bachelor/sample_data/split/database.txt', 500000)  # Split the file by 500,000 lines per file + the remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a98121c6-50a9-40e1-bab9-18fdbeacc09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chardet in /opt/conda/lib/python3.10/site-packages (5.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# wordLem_poS.txt has an encoding problem: it's encoded as ascii, but it contains characters beyond ascii codes (>127).\n",
    "%pip install chardet\n",
    "import chardet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b27ea03f-aa57-479d-b147-320807c1be35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing line 10000\n",
      "Processing line 20000\n",
      "Processing line 30000\n",
      "Processing line 40000\n",
      "Processing line 50000\n",
      "Processing line 60000\n",
      "Processing line 70000\n",
      "Processing line 80000\n",
      "Processing line 90000\n",
      "Processing line 100000\n",
      "Processing line 110000\n",
      "Processing line 120000\n",
      "Processing line 130000\n",
      "Processing line 140000\n",
      "Processing line 150000\n",
      "Processing line 160000\n",
      "Processing line 170000\n",
      "Processing line 180000\n",
      "Processing line 190000\n",
      "Processing line 200000\n",
      "Processing line 210000\n",
      "Processing line 220000\n",
      "Processing line 230000\n",
      "Processing line 240000\n",
      "Processing line 250000\n",
      "Processing line 260000\n",
      "Processing line 270000\n",
      "Processing line 280000\n",
      "Processing line 290000\n",
      "Processing line 300000\n",
      "Processing line 310000\n",
      "Processing line 320000\n",
      "Processing line 330000\n",
      "Processing line 340000\n",
      "Processing line 350000\n",
      "Processing line 360000\n",
      "Processing line 370000\n",
      "Processing line 380000\n",
      "Processing line 390000\n",
      "Processing line 400000\n",
      "Processing line 410000\n",
      "Processing line 420000\n",
      "Processing line 430000\n",
      "Processing line 440000\n",
      "Processing line 450000\n",
      "Processing line 460000\n",
      "Processing line 470000\n",
      "Processing line 480000\n",
      "Processing line 490000\n",
      "Processing line 500000\n",
      "Writing file /work/Bachelor/sample_data/split/wordLem_poS_1.txt\n",
      "Processing line 10000\n",
      "Processing line 20000\n",
      "Processing line 30000\n",
      "Processing line 40000\n",
      "Processing line 50000\n",
      "Processing line 60000\n",
      "Processing line 70000\n",
      "Processing line 80000\n",
      "Processing line 90000\n",
      "Processing line 100000\n",
      "Processing line 110000\n",
      "Processing line 120000\n",
      "Processing line 130000\n",
      "Processing line 140000\n",
      "Processing line 150000\n",
      "Processing line 160000\n",
      "Processing line 170000\n",
      "Processing line 180000\n",
      "Processing line 190000\n",
      "Processing line 200000\n",
      "Processing line 210000\n",
      "Processing line 220000\n",
      "Processing line 230000\n",
      "Processing line 240000\n",
      "Processing line 250000\n",
      "Processing line 260000\n",
      "Processing line 270000\n",
      "Processing line 280000\n",
      "Processing line 290000\n",
      "Processing line 300000\n",
      "Processing line 310000\n",
      "Processing line 320000\n",
      "Processing line 330000\n",
      "Processing line 340000\n",
      "Processing line 350000\n",
      "Processing line 360000\n",
      "Processing line 370000\n",
      "Processing line 380000\n",
      "Processing line 390000\n",
      "Processing line 400000\n",
      "Processing line 410000\n",
      "Processing line 420000\n",
      "Processing line 430000\n",
      "Processing line 440000\n",
      "Processing line 450000\n",
      "Processing line 460000\n",
      "Processing line 470000\n",
      "Processing line 480000\n",
      "Processing line 490000\n",
      "Processing line 500000\n",
      "Writing file /work/Bachelor/sample_data/split/wordLem_poS_2.txt\n",
      "Processing line 10000\n",
      "Processing line 20000\n",
      "Processing line 30000\n",
      "Processing line 40000\n",
      "Processing line 50000\n",
      "Processing line 60000\n",
      "Processing line 70000\n",
      "Processing line 80000\n",
      "Processing line 90000\n",
      "Processing line 100000\n",
      "Processing line 110000\n",
      "Processing line 120000\n",
      "Processing line 130000\n",
      "Processing line 140000\n",
      "Processing line 150000\n",
      "Processing line 160000\n",
      "Processing line 170000\n",
      "Processing line 180000\n",
      "Processing line 190000\n",
      "Processing line 200000\n",
      "Processing line 210000\n",
      "Processing line 220000\n",
      "Processing line 230000\n",
      "Processing line 240000\n",
      "Processing line 250000\n",
      "Processing line 260000\n",
      "Processing line 270000\n",
      "Processing line 280000\n",
      "Processing line 290000\n",
      "Processing line 300000\n",
      "Processing line 310000\n",
      "Processing line 320000\n",
      "Processing line 330000\n",
      "Processing line 340000\n",
      "Processing line 350000\n",
      "Processing line 360000\n",
      "Processing line 370000\n",
      "Processing line 380000\n",
      "Processing line 390000\n",
      "Processing line 400000\n",
      "Processing line 410000\n",
      "Processing line 420000\n",
      "Processing line 430000\n",
      "Processing line 440000\n",
      "Processing line 450000\n",
      "Processing line 460000\n",
      "Processing line 470000\n",
      "Processing line 480000\n",
      "Processing line 490000\n",
      "Processing line 500000\n",
      "Writing file /work/Bachelor/sample_data/split/wordLem_poS_3.txt\n",
      "Processing line 10000\n",
      "Processing line 20000\n",
      "Processing line 30000\n",
      "Processing line 40000\n",
      "Processing line 50000\n",
      "Processing line 60000\n",
      "Processing line 70000\n",
      "Processing line 80000\n",
      "Processing line 90000\n",
      "Processing line 100000\n",
      "Processing line 110000\n",
      "Processing line 120000\n",
      "Processing line 130000\n",
      "Processing line 140000\n",
      "Processing line 150000\n",
      "Processing line 160000\n",
      "Processing line 170000\n",
      "Processing line 180000\n",
      "Processing line 190000\n",
      "Processing line 200000\n",
      "Processing line 210000\n",
      "Processing line 220000\n",
      "Processing line 230000\n",
      "Processing line 240000\n",
      "Processing line 250000\n",
      "Processing line 260000\n",
      "Processing line 270000\n",
      "Processing line 280000\n",
      "Processing line 290000\n",
      "Processing line 300000\n",
      "Processing line 310000\n",
      "Processing line 320000\n",
      "Processing line 330000\n",
      "Processing line 340000\n",
      "Processing line 350000\n",
      "Processing line 360000\n",
      "Processing line 370000\n",
      "Processing line 380000\n",
      "Processing line 390000\n",
      "Processing line 400000\n",
      "Processing line 410000\n",
      "Processing line 420000\n",
      "Processing line 430000\n",
      "Processing line 440000\n",
      "Processing line 450000\n",
      "Writing final file /work/Bachelor/sample_data/split/wordLem_poS_4.txt\n"
     ]
    }
   ],
   "source": [
    "# # make function that can split wordLem_poS.txt file into smaller txt files - while fixing ecoding problem\n",
    "import os\n",
    "\n",
    "def split_file_by_lines(file_path, lines_per_file):\n",
    "    \"\"\"Splits a large text file into smaller files with a specific number of lines each.\"\"\"\n",
    "    \n",
    "    # Create output directory if it doesn't exist\n",
    "    output_folder = os.path.dirname(file_path)  # Get the directory of the input file\n",
    "    base_filename = os.path.splitext(os.path.basename(file_path))[0]  # Get the base name of the input file (without extension)\n",
    "\n",
    "    with open(file_path, 'r', encoding='ascii', errors='replace') as file:  # Open the file with ASCII encoding, replacing errors\n",
    "        file_count = 1\n",
    "        current_lines = []\n",
    "        \n",
    "        for line in file:\n",
    "            current_lines.append(line)\n",
    "            \n",
    "            # Print progress for debugging\n",
    "            if len(current_lines) % 10000 == 0:\n",
    "                print(f\"Processing line {len(current_lines)}\")\n",
    "            \n",
    "            # When we've collected enough lines, write them to a new file\n",
    "            if len(current_lines) == lines_per_file:\n",
    "                output_file_path = os.path.join(output_folder, f'{base_filename}_{file_count}.txt')\n",
    "                print(f\"Writing file {output_file_path}\")\n",
    "                with open(output_file_path, 'w', encoding='ascii', errors='replace') as new_file:  # Write with ASCII encoding and replace errors\n",
    "                    new_file.writelines(current_lines)\n",
    "                file_count += 1\n",
    "                current_lines = []  # Reset for the next file\n",
    "        \n",
    "        # Write any remaining lines to a final file\n",
    "        if current_lines:\n",
    "            output_file_path = os.path.join(output_folder, f'{base_filename}_{file_count}.txt')\n",
    "            print(f\"Writing final file {output_file_path}\")\n",
    "            with open(output_file_path, 'w', encoding='ascii', errors='replace') as new_file:\n",
    "                new_file.writelines(current_lines)\n",
    "\n",
    "# Example usage\n",
    "split_file_by_lines('/work/Bachelor/sample_data/split/wordLem_poS.txt', 500000)  # Split the file by 1,000,000 lines per file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999c1f04-3701-4476-8ba6-3d9ea344c55d",
   "metadata": {},
   "source": [
    "## HUZZA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d026f26-c93d-4830-88e0-db73358d8c7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
