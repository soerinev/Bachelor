{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0a6d2b8-3f0e-4583-ab30-d51b8870b4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: chardet in /opt/conda/lib/python3.10/site-packages (5.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: cchardet in /opt/conda/lib/python3.10/site-packages (2.1.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# import/load packages\n",
    "\n",
    "## install\n",
    "%pip install pandas\n",
    "%pip install chardet\n",
    "%pip install cchardet\n",
    "\n",
    "\n",
    "## import\n",
    "import os\n",
    "import pandas as pd\n",
    "import chardet\n",
    "import cchardet\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c75289c-3006-4c09-ac4c-82a0c7d84069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/work/Bachelor'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see directory\n",
    "os. getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316d81ce-3516-4de2-857f-de7a5611b279",
   "metadata": {},
   "source": [
    "## Check that dataframe structures are **proper**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50e3b07-f798-46e0-b913-5e1dae4fa4c3",
   "metadata": {},
   "source": [
    "## Testing 05-17 text.txt and sources.txt files from sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d43ea07-4775-4f32-ba0b-7068008213f9",
   "metadata": {},
   "source": [
    "### sources-17-05.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3495fb3-12fd-444a-be74-a74bee40d497",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>words</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>source</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18207168</td>\n",
       "      <td>2362</td>\n",
       "      <td>17-05-01</td>\n",
       "      <td>US</td>\n",
       "      <td>Huffington Post</td>\n",
       "      <td>http://www.huffingtonpost.com/entry/a-letter-t...</td>\n",
       "      <td>A letter to parents of expat children</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18207169</td>\n",
       "      <td>343</td>\n",
       "      <td>17-05-01</td>\n",
       "      <td>US</td>\n",
       "      <td>GoLocalProv</td>\n",
       "      <td>http://www.golocalprov.com/business/chafee-ste...</td>\n",
       "      <td>Chafee Steps Up Criticism of Raimondo's Econom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18207170</td>\n",
       "      <td>257</td>\n",
       "      <td>17-05-01</td>\n",
       "      <td>US</td>\n",
       "      <td>Engadget</td>\n",
       "      <td>https://www.engadget.com/2017/05/01/lab-grown-...</td>\n",
       "      <td>Lab-grown stem cells may carry an increased ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18207172</td>\n",
       "      <td>180</td>\n",
       "      <td>17-05-01</td>\n",
       "      <td>US</td>\n",
       "      <td>Northwest Herald</td>\n",
       "      <td>http://www.nwherald.com/2017/04/28/friends-of-...</td>\n",
       "      <td>Friends of McHenry County College Foundation t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18207174</td>\n",
       "      <td>630</td>\n",
       "      <td>17-05-01</td>\n",
       "      <td>US</td>\n",
       "      <td>GoLocalProv</td>\n",
       "      <td>http://www.golocalprov.com/politics/guest-mind...</td>\n",
       "      <td>Guest MINDSETTERT James Monteiro: Vote No in R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297859</th>\n",
       "      <td>18740662</td>\n",
       "      <td>304</td>\n",
       "      <td>17-05-31</td>\n",
       "      <td>JM</td>\n",
       "      <td>Jamaica Star Online</td>\n",
       "      <td>http://jamaica-star.com/article/news/20170531/...</td>\n",
       "      <td>Christopher Townsend is back on Munga's murder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297860</th>\n",
       "      <td>18742209</td>\n",
       "      <td>315</td>\n",
       "      <td>17-05-31</td>\n",
       "      <td>JM</td>\n",
       "      <td>Jamaica Gleaner</td>\n",
       "      <td>http://jamaica-gleaner.com/article/news/201705...</td>\n",
       "      <td>OUR proposes fixes to JPS after August 2016 bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297861</th>\n",
       "      <td>18742210</td>\n",
       "      <td>127</td>\n",
       "      <td>17-05-31</td>\n",
       "      <td>JM</td>\n",
       "      <td>Jamaica Star Online</td>\n",
       "      <td>http://jamaica-star.com/article/entertainment/...</td>\n",
       "      <td>Journalist curses Damian Marley in Kenya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297862</th>\n",
       "      <td>18742211</td>\n",
       "      <td>288</td>\n",
       "      <td>17-05-31</td>\n",
       "      <td>JM</td>\n",
       "      <td>Jamaica Star Online</td>\n",
       "      <td>http://jamaica-star.com/article/entertainment/...</td>\n",
       "      <td>DON'T PRAY FOR ME ... Pepita slams unworthy Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297863</th>\n",
       "      <td>18741456</td>\n",
       "      <td>175</td>\n",
       "      <td>17-05-31</td>\n",
       "      <td>JM</td>\n",
       "      <td>Jamaica Gleaner</td>\n",
       "      <td>http://jamaica-gleaner.com/article/entertainme...</td>\n",
       "      <td>Reggae could be added to UNESCO's list of Inta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>297864 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          textID  words      date country               source  \\\n",
       "0       18207168   2362  17-05-01      US      Huffington Post   \n",
       "1       18207169    343  17-05-01      US          GoLocalProv   \n",
       "2       18207170    257  17-05-01      US             Engadget   \n",
       "3       18207172    180  17-05-01      US     Northwest Herald   \n",
       "4       18207174    630  17-05-01      US          GoLocalProv   \n",
       "...          ...    ...       ...     ...                  ...   \n",
       "297859  18740662    304  17-05-31      JM  Jamaica Star Online   \n",
       "297860  18742209    315  17-05-31      JM      Jamaica Gleaner   \n",
       "297861  18742210    127  17-05-31      JM  Jamaica Star Online   \n",
       "297862  18742211    288  17-05-31      JM  Jamaica Star Online   \n",
       "297863  18741456    175  17-05-31      JM      Jamaica Gleaner   \n",
       "\n",
       "                                                      url  \\\n",
       "0       http://www.huffingtonpost.com/entry/a-letter-t...   \n",
       "1       http://www.golocalprov.com/business/chafee-ste...   \n",
       "2       https://www.engadget.com/2017/05/01/lab-grown-...   \n",
       "3       http://www.nwherald.com/2017/04/28/friends-of-...   \n",
       "4       http://www.golocalprov.com/politics/guest-mind...   \n",
       "...                                                   ...   \n",
       "297859  http://jamaica-star.com/article/news/20170531/...   \n",
       "297860  http://jamaica-gleaner.com/article/news/201705...   \n",
       "297861  http://jamaica-star.com/article/entertainment/...   \n",
       "297862  http://jamaica-star.com/article/entertainment/...   \n",
       "297863  http://jamaica-gleaner.com/article/entertainme...   \n",
       "\n",
       "                                                    title  \n",
       "0                   A letter to parents of expat children  \n",
       "1       Chafee Steps Up Criticism of Raimondo's Econom...  \n",
       "2       Lab-grown stem cells may carry an increased ri...  \n",
       "3       Friends of McHenry County College Foundation t...  \n",
       "4       Guest MINDSETTERT James Monteiro: Vote No in R...  \n",
       "...                                                   ...  \n",
       "297859  Christopher Townsend is back on Munga's murder...  \n",
       "297860  OUR proposes fixes to JPS after August 2016 bl...  \n",
       "297861           Journalist curses Damian Marley in Kenya  \n",
       "297862  DON'T PRAY FOR ME ... Pepita slams unworthy Ch...  \n",
       "297863  Reggae could be added to UNESCO's list of Inta...  \n",
       "\n",
       "[297864 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sources\n",
    "\n",
    "# define file path\n",
    "file_path = \"/work/Bachelor/sample_data/dropbox/sources-17-05.txt\"\n",
    "\n",
    "# read csv file into dataframe\n",
    "df_sources_17_05 = pd.read_csv(file_path, delimiter='\\t', encoding='ISO-8859-1')\n",
    "\n",
    "# define column names\n",
    "column_names = [\"textID\", \"words\", \"date\", \"country\", \"source\", \"url\", \"title\"]\n",
    "\n",
    "# assign new column names to the dataframe\n",
    "df_sources_17_05.columns = column_names\n",
    "df_sources_17_05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9012d23f-a78d-4822-873d-49831feffaa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country\n",
      "IN    31756\n",
      "CA    30205\n",
      "US    26663\n",
      "GB    26223\n",
      "IE    25204\n",
      "NG    21151\n",
      "AU    20726\n",
      "NZ    18999\n",
      "ZA    18324\n",
      "MY    17759\n",
      "SG    16959\n",
      "PH    14018\n",
      "PK    10431\n",
      "KE     7038\n",
      "GH     6066\n",
      "HK     1853\n",
      "LK     1762\n",
      "JM     1352\n",
      "BD     1279\n",
      "TZ       96\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check how many articles there are from each country\n",
    "country_counts = df_sources_17_05['country'].value_counts()\n",
    "print(country_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28f17250-7da4-4495-9fdd-67646a2c540e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26663"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter to only include sources from the US\n",
    "dropbox_sources_17_05_US = df_sources_17_05[df_sources_17_05['country'] == 'US']\n",
    "\n",
    "# check length to compare with the dropbox_text file\n",
    "len(dropbox_sources_17_05_US)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f602c596-487c-43c3-95b7-e0b316f664a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dropbox_sources_17_05_US' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m output_file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/work/Bachelor/sample_data/stopthenonsense/dropbox_sources_17_05_US.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Save the filtered DataFrame as a CSV file\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mdropbox_sources_17_05_US\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(output_file_path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dropbox_sources_17_05_US' is not defined"
     ]
    }
   ],
   "source": [
    "# save as csv to check that articles aren't nested in each other\n",
    "\n",
    "# Define the file path where you want to save the CSV\n",
    "output_file_path = \"/work/Bachelor/sample_data/stopthenonsense/dropbox_sources_17_05_US.csv\"\n",
    "\n",
    "# Save the filtered DataFrame as a CSV file\n",
    "dropbox_sources_17_05_US.to_csv(output_file_path, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac92052-2fb6-4401-9e62-c379ad68f2f6",
   "metadata": {},
   "source": [
    "### text_17-05-US.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2dccc89d-96b3-4c1e-aca3-169fdaa2afff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18207159</td>\n",
       "      <td>It appears that right now is a pretty good tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18207168</td>\n",
       "      <td>A letter to parents of expat children  Parenti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18207169</td>\n",
       "      <td>Chafee Steps Up Criticism of Raimondo 's Econo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18207170</td>\n",
       "      <td>Lab-grown stem cells may carry an increased ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18207172</td>\n",
       "      <td>Friends of McHenry County College Foundation t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27082</th>\n",
       "      <td>18745486</td>\n",
       "      <td>1954 : American film star Marilyn Monroe ( 192...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27083</th>\n",
       "      <td>18745488</td>\n",
       "      <td>On the two-year anniversary of his murder , Ka...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27084</th>\n",
       "      <td>18745489</td>\n",
       "      <td>Artists file lawsuit against city of Atlanta o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27085</th>\n",
       "      <td>18745490</td>\n",
       "      <td>MONTESANO , Wash . -- James Walker , 31 , of H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27086</th>\n",
       "      <td>18745491</td>\n",
       "      <td>Out to the track for our KSFY/Taco John 's Ath...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27087 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         textID                                               text\n",
       "0      18207159  It appears that right now is a pretty good tim...\n",
       "1      18207168  A letter to parents of expat children  Parenti...\n",
       "2      18207169  Chafee Steps Up Criticism of Raimondo 's Econo...\n",
       "3      18207170  Lab-grown stem cells may carry an increased ri...\n",
       "4      18207172  Friends of McHenry County College Foundation t...\n",
       "...         ...                                                ...\n",
       "27082  18745486  1954 : American film star Marilyn Monroe ( 192...\n",
       "27083  18745488  On the two-year anniversary of his murder , Ka...\n",
       "27084  18745489  Artists file lawsuit against city of Atlanta o...\n",
       "27085  18745490  MONTESANO , Wash . -- James Walker , 31 , of H...\n",
       "27086  18745491  Out to the track for our KSFY/Taco John 's Ath...\n",
       "\n",
       "[27087 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not\n",
    "# text\n",
    "\n",
    "# Define file path\n",
    "file_path = \"/work/Bachelor/sample_data/dropbox/text_17-05-US.txt\"\n",
    "\n",
    "# Open the file and read its contents into a string\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    raw_text = file.read()  # Read all text data from the file\n",
    "\n",
    "# Step 1: Split the text into articles based on '@@' markers\n",
    "articles = raw_text.split('@@')[1:]  # Split the text by '@@' and ignore the first empty item\n",
    "\n",
    "# Lists to store extracted data\n",
    "text_ids = []  # Initialize a list to store article IDs\n",
    "clean_texts = []  # Initialize a list to store cleaned article texts\n",
    "\n",
    "# Step 2: Process each article\n",
    "for article in articles:  # Loop through each article in the list\n",
    "    # Extract article ID (the number right after @@)\n",
    "    article_id_match = re.match(r'(\\d+)', article)  # Match numbers at the beginning of the article\n",
    "    text_id = article_id_match.group(1) if article_id_match else None  # Extract ID if match found, else None\n",
    "\n",
    "    # Remove the ID and any leading characters (up to the first space)\n",
    "    cleaned_article = re.sub(r'^\\d+\\s*', '', article)  # Remove leading numbers and spaces\n",
    "\n",
    "    # Remove HTML-like tags (<h>, <p>, etc.)\n",
    "    cleaned_article = re.sub(r'<[^>]+>', '', cleaned_article).strip()  # Remove HTML tags and extra spaces\n",
    "\n",
    "    # Append extracted data to lists\n",
    "    text_ids.append(text_id)  # Add the ID to the text_ids list\n",
    "    clean_texts.append(cleaned_article)  # Add the cleaned text to the clean_texts list\n",
    "\n",
    "# Step 3: Create a DataFrame to store the structured data\n",
    "dropbox_text_17_05 = pd.DataFrame({\n",
    "    'textID': text_ids,  # Column with article IDs\n",
    "    'text': clean_texts   # Column with cleaned article texts\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "dropbox_text_17_05  # Output the DataFrame to view structured data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "35173f34-8d7c-49c6-98a3-63dc6e5778ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27087 27087\n",
      "18207159\n",
      "It appears that right now is a pretty good time to be a band called Dawes. With the release of their\n",
      "\n",
      "18207168\n",
      "Parenting is fraught with anxiety, joys, challenges.... Parenting expat children is a different ball\n",
      "\n",
      "18207169\n",
      "In a letter sent to members of the Board of the Commerce Corporation, former Governor Lincoln Chafee\n",
      "\n",
      "18207170\n",
      "If you've followed the latest medical research, you know that stem cells are a big deal. They let yo\n",
      "\n",
      "18207172\n",
      "The Friends of McHenry County College Foundation is hosting its 2017 Friends of MCC Foundation Golf \n",
      "\n",
      "18207174\n",
      "I write to go on the record and say that I've been a Ward 3 resident probably longer than at least 9\n",
      "\n",
      "18207178\n",
      "Connor Mitchell, right, works on a computer at a cafe in San Francisco on April 13, 2017. With colle\n",
      "\n",
      "18207182\n",
      "Personal hero and why: My dad, because he is a volunteer firefighter and gives his free time to help\n",
      "\n",
      "18207185\n",
      "Students named in the complaints that disqualified former Student Association presidential candidate\n",
      "\n",
      "18207187\n",
      "Resident advisors at GW may not be part of a union now, but they have the chance to make history thi\n",
      "\n",
      "18207188\n",
      "By CYNTHIA TUCKER\n",
      "1:07 am\n",
      "\"\" Build that wall! \"\"\n",
      "That was one of the more popular rallying cries at \n",
      "\n",
      "18207191\n",
      "By Robert Ashley, M.D. For The Gazette\n",
      "21 hrs ago\n",
      "Dear Doctor: Which pain reliever is safer -- aceta\n",
      "\n",
      "18207192\n",
      "Take a step back in time to the summer of 1980 with Brooklyn-born photographer Jamel Shabazz's upcom\n",
      "\n",
      "18207193\n",
      "AGILE THERAPEUTICS INC ( NYSE:AGRX ) reached 97.25% versus a 1-year low price of $1.82. The stock wa\n",
      "\n",
      "18207194\n",
      "It's not as simple as the textbooks say.\n",
      "MIKE MCRAE\n",
      "1 MAY 2017\n",
      "As complex as the human brain is, it \n",
      "\n",
      "18207195\n",
      "On April 4, the world's largest tunnel boring machine broke through to the open air after almost fou\n",
      "\n",
      "18207196\n",
      "A rib-tickling homage to the gumshoe shows of yesteryear, with an endearingly daffy mindset.\n",
      "Back in\n",
      "\n",
      "18207197\n",
      "Become a digital subscriber today and enjoy unlimited access to the Omaha World-Herald anytime, anyw\n",
      "\n",
      "18207198\n",
      "For young people, the power to choose a path away from violence can come from digital tech\n",
      "Students \n",
      "\n",
      "18207199\n",
      "Levi Wingard never expected to make it into the Elyria Sports Hall of Fame. \"\" I was so surprised wh\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8261</th>\n",
       "      <td>18363418</td>\n",
       "      <td>TWIN FALLS -- Businesses that have a skills ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373</th>\n",
       "      <td>18232116</td>\n",
       "      <td>Approximately one hundred Internet years ago -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22100</th>\n",
       "      <td>18643620</td>\n",
       "      <td>CLEVELAND -- As the nation's deadly opioid cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2363</th>\n",
       "      <td>18251282</td>\n",
       "      <td>The old saying in regards to Abraham Lincoln's...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20903</th>\n",
       "      <td>18619016</td>\n",
       "      <td>A secret document that officials say played a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24461</th>\n",
       "      <td>18687854</td>\n",
       "      <td>Traffic backups on Oracle Road, like this one ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6884</th>\n",
       "      <td>18334023</td>\n",
       "      <td>Ahead of a site visit by the International Oly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6544</th>\n",
       "      <td>18326663</td>\n",
       "      <td>The law has to go through further drafting by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357</th>\n",
       "      <td>18231485</td>\n",
       "      <td>\"\" It was awful to watch that.... People shoul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26601</th>\n",
       "      <td>18736927</td>\n",
       "      <td>Updated: May 31, 2017 - 1:14 PM\\nPITTSBURGH - ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         textID                                               body\n",
       "8261   18363418  TWIN FALLS -- Businesses that have a skills ga...\n",
       "1373   18232116  Approximately one hundred Internet years ago -...\n",
       "22100  18643620  CLEVELAND -- As the nation's deadly opioid cri...\n",
       "2363   18251282  The old saying in regards to Abraham Lincoln's...\n",
       "20903  18619016  A secret document that officials say played a ...\n",
       "24461  18687854  Traffic backups on Oracle Road, like this one ...\n",
       "6884   18334023  Ahead of a site visit by the International Oly...\n",
       "6544   18326663  The law has to go through further drafting by ...\n",
       "1357   18231485  \"\" It was awful to watch that.... People shoul...\n",
       "26601  18736927  Updated: May 31, 2017 - 1:14 PM\\nPITTSBURGH - ..."
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define file path\n",
    "file_path = \"/work/Bachelor/sample_data/dropbox/text_17-05-US.txt\"\n",
    "\n",
    "# open the file and read its contents into a string\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    raw_text = file.read()  # Read all text data from the file\n",
    "\n",
    "sample = raw_text\n",
    "sample = re.sub(\" ([.,?!':])\", r\"\\1\", sample) # punctuation characters are all needlessly preceded by a space, remove that space\n",
    "sample = re.sub(\"@ @ @ @ @ @ @ @ @ @\", \"CENSORED\", sample) # replace the keyword chosen to mark words or entities that have been censored\n",
    "\n",
    "# Step 1: Split the text into articles based on '@@' markers\n",
    "article_ids = re.findall(r\"@@(\\d+)\", sample) # extract list of all article IDs by matching pattern of any sequence of digits following exactly two @\n",
    "articles = re.split(r'\"?@@\\d+ ', sample)[1:] # split articles on article IDs, i.e. a sequence of digits preceded by exactly two @s and sometimes a quotation mark preceding that\n",
    "articles = [art[art.find(\"<p> \") + 4:].strip().replace(\" <p> \", \"\\n\") for art in articles] # for each article, skip to the first paragraph tag to exclude heading/title text, then replace subsequent markers for new paragraphs with line breaks \n",
    "\n",
    "print(len(article_ids), len(articles)) # check that we found equally many IDs and article bodies\n",
    "\n",
    "articles_US = pd.DataFrame(data = dict(textID = article_ids, body = articles)) # create dataframe with extracted IDs and corresponding article contents\n",
    "articles_US[\"textID\"] = articles_US[\"textID\"].astype(int) # cast textIDs to int to enable merging with `sources` dataframe\n",
    "articles_US.sample(10) # sample ten random rows from the dataframe to examine whether things look as expected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cb4f039d-5517-428e-ae6d-077d5faba5c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>words</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>source</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18207168</td>\n",
       "      <td>2362</td>\n",
       "      <td>17-05-01</td>\n",
       "      <td>US</td>\n",
       "      <td>Huffington Post</td>\n",
       "      <td>http://www.huffingtonpost.com/entry/a-letter-t...</td>\n",
       "      <td>A letter to parents of expat children</td>\n",
       "      <td>Parenting is fraught with anxiety, joys, chall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18207169</td>\n",
       "      <td>343</td>\n",
       "      <td>17-05-01</td>\n",
       "      <td>US</td>\n",
       "      <td>GoLocalProv</td>\n",
       "      <td>http://www.golocalprov.com/business/chafee-ste...</td>\n",
       "      <td>Chafee Steps Up Criticism of Raimondo's Econom...</td>\n",
       "      <td>In a letter sent to members of the Board of th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18207170</td>\n",
       "      <td>257</td>\n",
       "      <td>17-05-01</td>\n",
       "      <td>US</td>\n",
       "      <td>Engadget</td>\n",
       "      <td>https://www.engadget.com/2017/05/01/lab-grown-...</td>\n",
       "      <td>Lab-grown stem cells may carry an increased ri...</td>\n",
       "      <td>If you've followed the latest medical research...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18207172</td>\n",
       "      <td>180</td>\n",
       "      <td>17-05-01</td>\n",
       "      <td>US</td>\n",
       "      <td>Northwest Herald</td>\n",
       "      <td>http://www.nwherald.com/2017/04/28/friends-of-...</td>\n",
       "      <td>Friends of McHenry County College Foundation t...</td>\n",
       "      <td>The Friends of McHenry County College Foundati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18207174</td>\n",
       "      <td>630</td>\n",
       "      <td>17-05-01</td>\n",
       "      <td>US</td>\n",
       "      <td>GoLocalProv</td>\n",
       "      <td>http://www.golocalprov.com/politics/guest-mind...</td>\n",
       "      <td>Guest MINDSETTERT James Monteiro: Vote No in R...</td>\n",
       "      <td>I write to go on the record and say that I've ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26658</th>\n",
       "      <td>18745486</td>\n",
       "      <td>1212</td>\n",
       "      <td>17-05-31</td>\n",
       "      <td>US</td>\n",
       "      <td>OCRegister</td>\n",
       "      <td>http://www.ocregister.com/2017/05/31/rememberi...</td>\n",
       "      <td>Remembering Marilyn Monroe on anniversary of h...</td>\n",
       "      <td>1954: American film star Marilyn Monroe ( 1926...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26659</th>\n",
       "      <td>18745488</td>\n",
       "      <td>424</td>\n",
       "      <td>17-05-31</td>\n",
       "      <td>US</td>\n",
       "      <td>fox4kc.com</td>\n",
       "      <td>http://fox4kc.com/2017/05/31/on-the-two-year-a...</td>\n",
       "      <td>On the two-year anniversary of his murder, Kan...</td>\n",
       "      <td>RAYTOWN, Mo. -- A 3-year-old's siblings and mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26660</th>\n",
       "      <td>18745489</td>\n",
       "      <td>405</td>\n",
       "      <td>17-05-31</td>\n",
       "      <td>US</td>\n",
       "      <td>FOX 5 Atlanta</td>\n",
       "      <td>http://www.fox5atlanta.com/news/258189601-story</td>\n",
       "      <td>Artists file lawsuit against city of Atlanta o...</td>\n",
       "      <td>ATLANTA - A group of artists have drawn a lega...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26661</th>\n",
       "      <td>18745490</td>\n",
       "      <td>458</td>\n",
       "      <td>17-05-31</td>\n",
       "      <td>US</td>\n",
       "      <td>Q13 FOX</td>\n",
       "      <td>http://q13fox.com/2017/05/31/man-accused-of-ba...</td>\n",
       "      <td>Man accused of backing truck over 2 men, killi...</td>\n",
       "      <td>MONTESANO, Wash. -- James Walker, 31, of Hoqui...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26662</th>\n",
       "      <td>18745491</td>\n",
       "      <td>150</td>\n",
       "      <td>17-05-31</td>\n",
       "      <td>US</td>\n",
       "      <td>KSFY</td>\n",
       "      <td>http://www.ksfy.com/content/sports/Brandon-Val...</td>\n",
       "      <td>Brandon Valley senior Jakob Hanna named KSFY/T...</td>\n",
       "      <td>Out to the track for our KSFY/Taco John's Athl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26663 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         textID  words      date country            source  \\\n",
       "0      18207168   2362  17-05-01      US   Huffington Post   \n",
       "1      18207169    343  17-05-01      US       GoLocalProv   \n",
       "2      18207170    257  17-05-01      US          Engadget   \n",
       "3      18207172    180  17-05-01      US  Northwest Herald   \n",
       "4      18207174    630  17-05-01      US       GoLocalProv   \n",
       "...         ...    ...       ...     ...               ...   \n",
       "26658  18745486   1212  17-05-31      US        OCRegister   \n",
       "26659  18745488    424  17-05-31      US        fox4kc.com   \n",
       "26660  18745489    405  17-05-31      US     FOX 5 Atlanta   \n",
       "26661  18745490    458  17-05-31      US           Q13 FOX   \n",
       "26662  18745491    150  17-05-31      US              KSFY   \n",
       "\n",
       "                                                     url  \\\n",
       "0      http://www.huffingtonpost.com/entry/a-letter-t...   \n",
       "1      http://www.golocalprov.com/business/chafee-ste...   \n",
       "2      https://www.engadget.com/2017/05/01/lab-grown-...   \n",
       "3      http://www.nwherald.com/2017/04/28/friends-of-...   \n",
       "4      http://www.golocalprov.com/politics/guest-mind...   \n",
       "...                                                  ...   \n",
       "26658  http://www.ocregister.com/2017/05/31/rememberi...   \n",
       "26659  http://fox4kc.com/2017/05/31/on-the-two-year-a...   \n",
       "26660    http://www.fox5atlanta.com/news/258189601-story   \n",
       "26661  http://q13fox.com/2017/05/31/man-accused-of-ba...   \n",
       "26662  http://www.ksfy.com/content/sports/Brandon-Val...   \n",
       "\n",
       "                                                   title  \\\n",
       "0                  A letter to parents of expat children   \n",
       "1      Chafee Steps Up Criticism of Raimondo's Econom...   \n",
       "2      Lab-grown stem cells may carry an increased ri...   \n",
       "3      Friends of McHenry County College Foundation t...   \n",
       "4      Guest MINDSETTERT James Monteiro: Vote No in R...   \n",
       "...                                                  ...   \n",
       "26658  Remembering Marilyn Monroe on anniversary of h...   \n",
       "26659  On the two-year anniversary of his murder, Kan...   \n",
       "26660  Artists file lawsuit against city of Atlanta o...   \n",
       "26661  Man accused of backing truck over 2 men, killi...   \n",
       "26662  Brandon Valley senior Jakob Hanna named KSFY/T...   \n",
       "\n",
       "                                                    body  \n",
       "0      Parenting is fraught with anxiety, joys, chall...  \n",
       "1      In a letter sent to members of the Board of th...  \n",
       "2      If you've followed the latest medical research...  \n",
       "3      The Friends of McHenry County College Foundati...  \n",
       "4      I write to go on the record and say that I've ...  \n",
       "...                                                  ...  \n",
       "26658  1954: American film star Marilyn Monroe ( 1926...  \n",
       "26659  RAYTOWN, Mo. -- A 3-year-old's siblings and mo...  \n",
       "26660  ATLANTA - A group of artists have drawn a lega...  \n",
       "26661  MONTESANO, Wash. -- James Walker, 31, of Hoqui...  \n",
       "26662  Out to the track for our KSFY/Taco John's Athl...  \n",
       "\n",
       "[26663 rows x 8 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined = dropbox_sources_17_05_US.merge(articles_US, on = \"textID\", how = \"left\") # join sources dataframe with their corresponding article content using the textIDs, keeping only the articles where source information was available\n",
    "joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ad1028b-92f6-44d9-bebe-27e983511772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         textID  X.words      date country            source  \\\n",
      "0      18207168     2362  17-05-01      US   Huffington Post   \n",
      "1      18207169      343  17-05-01      US       GoLocalProv   \n",
      "2      18207170      257  17-05-01      US          Engadget   \n",
      "3      18207172      180  17-05-01      US  Northwest Herald   \n",
      "4      18207174      630  17-05-01      US       GoLocalProv   \n",
      "...         ...      ...       ...     ...               ...   \n",
      "26658  18745486     1212  17-05-31      US        OCRegister   \n",
      "26659  18745488      424  17-05-31      US        fox4kc.com   \n",
      "26660  18745489      405  17-05-31      US     FOX 5 Atlanta   \n",
      "26661  18745490      458  17-05-31      US           Q13 FOX   \n",
      "26662  18745491      150  17-05-31      US              KSFY   \n",
      "\n",
      "                                                     url  \\\n",
      "0      http://www.huffingtonpost.com/entry/a-letter-t...   \n",
      "1      http://www.golocalprov.com/business/chafee-ste...   \n",
      "2      https://www.engadget.com/2017/05/01/lab-grown-...   \n",
      "3      http://www.nwherald.com/2017/04/28/friends-of-...   \n",
      "4      http://www.golocalprov.com/politics/guest-mind...   \n",
      "...                                                  ...   \n",
      "26658  http://www.ocregister.com/2017/05/31/rememberi...   \n",
      "26659  http://fox4kc.com/2017/05/31/on-the-two-year-a...   \n",
      "26660    http://www.fox5atlanta.com/news/258189601-story   \n",
      "26661  http://q13fox.com/2017/05/31/man-accused-of-ba...   \n",
      "26662  http://www.ksfy.com/content/sports/Brandon-Val...   \n",
      "\n",
      "                                                   title  \\\n",
      "0                  A letter to parents of expat children   \n",
      "1      Chafee Steps Up Criticism of Raimondo's Econom...   \n",
      "2      Lab-grown stem cells may carry an increased ri...   \n",
      "3      Friends of McHenry County College Foundation t...   \n",
      "4      Guest MINDSETTERT James Monteiro: Vote No in R...   \n",
      "...                                                  ...   \n",
      "26658  Remembering Marilyn Monroe on anniversary of h...   \n",
      "26659  On the two-year anniversary of his murder, Kan...   \n",
      "26660  Artists file lawsuit against city of Atlanta o...   \n",
      "26661  Man accused of backing truck over 2 men, killi...   \n",
      "26662  Brandon Valley senior Jakob Hanna named KSFY/T...   \n",
      "\n",
      "                                                    text  \n",
      "0      A letter to parents of expat children  Parenti...  \n",
      "1      Chafee Steps Up Criticism of Raimondo 's Econo...  \n",
      "2      Lab-grown stem cells may carry an increased ri...  \n",
      "3      Friends of McHenry County College Foundation t...  \n",
      "4      I write to go on the record and say that I 've...  \n",
      "...                                                  ...  \n",
      "26658  1954 : American film star Marilyn Monroe ( 192...  \n",
      "26659  On the two-year anniversary of his murder , Ka...  \n",
      "26660  Artists file lawsuit against city of Atlanta o...  \n",
      "26661  MONTESANO , Wash . -- James Walker , 31 , of H...  \n",
      "26662  Out to the track for our KSFY/Taco John 's Ath...  \n",
      "\n",
      "[26663 rows x 8 columns]\n",
      "26663\n"
     ]
    }
   ],
   "source": [
    "# not\n",
    "# ensure both 'textID' columns have the same data type (convert to string)\n",
    "dropbox_sources_17_05_US.loc[:, 'textID'] = dropbox_sources_17_05_US['textID'].astype(str)\n",
    "dropbox_text_17_05.loc[:, 'textID'] = dropbox_text_17_05['textID'].astype(str)\n",
    "\n",
    "# merge the two DataFrames on 'textID'\n",
    "combined_dropbox_articles = pd.merge(dropbox_sources_17_05_US, dropbox_text_17_05, on='textID', how='inner')\n",
    "\n",
    "# display\n",
    "print(combined_dropbox_articles)\n",
    "print(len(combined_dropbox_articles))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3399b02e-3370-42b9-bd93-ab3832364b50",
   "metadata": {},
   "source": [
    "### Stuff is happening!!! 26,663 sources, and 27,087 texts.\n",
    "### Okay also cool, there are as many rows in the combined dataframe as there are in the source dataframe. So the text dataframe must be split correctly. Maybe something's up with the sources then...👩‍🍳 check out tomorrow, and also test these things on the sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a130573-2b59-4296-baad-830a743325ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# playground 2 - make csv before filtering\n",
    "\n",
    "# sources\n",
    "file_path = \"/work/Bachelor/sample_data/dropbox/sources-17-05.txt\"\n",
    "\n",
    "#df_sources_17_05 = pd.read_csv(file_path, delimiter='\\t', encoding='ISO-8859-1')\n",
    "#print(df_sources_17_05)\n",
    "\n",
    "# Define the file path (you would adjust this to your actual file path)\n",
    "file_path = \"/work/Bachelor/sample_data/dropbox/text_17-05-US.txt\"\n",
    "\n",
    "# Open the file and read its contents into a string\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    raw_text = file.read()\n",
    "\n",
    "# Step 1: Split the text into articles based on '@@' markers\n",
    "articles = raw_text.split('@@')[1:]  # Skip the first empty split\n",
    "\n",
    "# Lists to store extracted data\n",
    "text_ids = []\n",
    "clean_texts = []\n",
    "\n",
    "# Step 2: Process each article\n",
    "for article in articles:\n",
    "    # Extract article ID (the number right after @@)\n",
    "    article_id_match = re.match(r'(\\d+)', article)\n",
    "    text_id = article_id_match.group(1) if article_id_match else None\n",
    "\n",
    "    # Remove the ID and any leading characters (up to the first space)\n",
    "    cleaned_article = re.sub(r'^\\d+\\s*', '', article)\n",
    "\n",
    "    # Remove HTML-like tags (<h>, <p>, etc.)\n",
    "    cleaned_article = re.sub(r'<[^>]+>', '', cleaned_article).strip()\n",
    "\n",
    "    # Append extracted data to lists\n",
    "    text_ids.append(text_id)\n",
    "    clean_texts.append(cleaned_article)\n",
    "\n",
    "# Step 3: Create a DataFrame to store the structured data\n",
    "df_text_17_05 = pd.DataFrame({\n",
    "    'textID': text_ids,\n",
    "    'text': clean_texts\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_text_17_05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "50cfe991-4fa5-4fc1-8768-aa2b47e1364b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as csv to check that articles aren't nested in each other\n",
    "\n",
    "# Define the file path where you want to save the CSV\n",
    "output_file_path = \"/work/Bachelor/sample_data/stopthenonsense/dropbox_text_17_05.csv\"\n",
    "\n",
    "# Save the filtered DataFrame as a CSV file\n",
    "df_text_17_05.to_csv(output_file_path, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e62b2ac-6d5d-43f2-8e17-40b95880f1fd",
   "metadata": {},
   "source": [
    "### I think it's good but fuck knows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529daae5-fe32-4e76-8776-ae1a90d44cb7",
   "metadata": {},
   "source": [
    "## Testing original text.txt and sources.txt files from sample data👩‍🍳"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "418b45ad-7283-406b-908d-9b843a555340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   textID  X.words        date country               source  \\\n",
      "0   11241      397  13.01.2006      US               Kotaku   \n",
      "1   11242      757  13.01.2006      US       Michigan Radio   \n",
      "2   11243      755  13.01.2006      US  New York Daily News   \n",
      "3   11244     1677  13.01.2006      US       OregonLive.com   \n",
      "4   21242      794  13.01.2011      US         Ars Technica   \n",
      "\n",
      "                                                 url  \\\n",
      "0  http://kotaku.com/5973495/author-of-the-warrio...   \n",
      "1  http://michiganradio.org/post/thats-what-they-...   \n",
      "2  http://www.nydailynews.com/life-style/eats/bes...   \n",
      "3  http://www.oregonlive.com/performance/index.ss...   \n",
      "4  http://arstechnica.com/gadgets/2013/01/ask-ars...   \n",
      "\n",
      "                                               title  \n",
      "0  Author of The Warriors, Cult Film Adapted to H...  \n",
      "1  That's What They Say: Dialect Society chooses ...  \n",
      "2                        Best of New York: Croissant  \n",
      "3  Reflecting on a quarter-century of growth in P...  \n",
      "4  Ask Ars: Does Facebook auto-delete content aft...  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2960"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the sources.csv that was made from excel and r\n",
    "file_path = \"/work/Bachelor/sample_data/stopthenonsense/sources.csv\"\n",
    "df_sources_fr = pd.read_csv(file_path)\n",
    "\n",
    "print(df_sources_fr.head())  # Display the first few rows of the loaded DataFrame\n",
    "len(df_sources_fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fddc5a3-2192-4df0-ab69-b22c1146acb3",
   "metadata": {},
   "source": [
    "### I think this 👆 is the proper sources_csv file<33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "62a01d86-29ca-4d3c-b87e-1cb660f9dc1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        textID                                               text\n",
      "0        11241  Sol Yurick , the writer whose 1965 novel \" The...\n",
      "1        11242  That 's What They Say : Dialect Society choose...\n",
      "2        11243  A sublime croissant at French Tart in Grant Ci...\n",
      "3        11244  Reflecting on a quarter-century of growth in P...\n",
      "4        21242  Ask Ars : Does Facebook auto-delete content af...\n",
      "...        ...                                                ...\n",
      "2909  15281244  Did you know that Prime Minister Narendra Modi...\n",
      "2910  15291240  Council voted Tuesday to support a new $30 per...\n",
      "2911  15291242  News Local  $5M funding boost for six projects...\n",
      "2912  15291243  A closed-door council meeting that reversed th...\n",
      "2913  15291244  ?  Burrows helps Canucks beat Rangers 5-3 to e...\n",
      "\n",
      "[2914 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# text\n",
    "\n",
    "# Define the file path (you would adjust this to your actual file path)\n",
    "file_path = \"/work/Bachelor/sample_data/text.txt\"\n",
    "\n",
    "# Open the file and read its contents into a string\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    raw_text = file.read()\n",
    "\n",
    "# Step 1: Split the text into articles based on '@@' markers\n",
    "articles = raw_text.split('@@')[1:]  # Skip the first empty split\n",
    "\n",
    "# Lists to store extracted data\n",
    "text_ids = []\n",
    "clean_texts = []\n",
    "\n",
    "# Step 2: Process each article\n",
    "for article in articles:\n",
    "    # Extract article ID (the number right after @@)\n",
    "    article_id_match = re.match(r'(\\d+)', article)\n",
    "    text_id = article_id_match.group(1) if article_id_match else None\n",
    "    \n",
    "\n",
    "    # Remove the ID and any leading characters (up to the first space)\n",
    "    cleaned_article = re.sub(r'^\\d+\\s*', '', article)\n",
    "\n",
    "    # Remove HTML-like tags (<h>, <p>, etc.)\n",
    "    cleaned_article = re.sub(r'<[^>]+>', '', cleaned_article).strip()\n",
    "\n",
    "    # Append extracted data to lists\n",
    "    text_ids.append(text_id)\n",
    "    clean_texts.append(cleaned_article)\n",
    "\n",
    "# Step 3: Create a DataFrame to store the structured data\n",
    "df_text = pd.DataFrame({\n",
    "    'textID': text_ids,\n",
    "    'text': clean_texts\n",
    "})\n",
    "\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14106510-83c0-45a8-8095-08c95598107d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        textID                                               text\n",
      "0        11241  Sol Yurick , the writer whose 1965 novel \" The...\n",
      "1        11242  That 's What They Say : Dialect Society choose...\n",
      "2        11243  A sublime croissant at French Tart in Grant Ci...\n",
      "3        11244  Reflecting on a quarter-century of growth in P...\n",
      "4        21242  Ask Ars : Does Facebook auto-delete content af...\n",
      "...        ...                                                ...\n",
      "2909  15281244  Did you know that Prime Minister Narendra Modi...\n",
      "2910  15291240  Council voted Tuesday to support a new $30 per...\n",
      "2911  15291242  News Local  $5M funding boost for six projects...\n",
      "2912  15291243  A closed-door council meeting that reversed th...\n",
      "2913  15291244  ?  Burrows helps Canucks beat Rangers 5-3 to e...\n",
      "\n",
      "[2914 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# playground 0\n",
    "\n",
    "# text\n",
    "\n",
    "# Define file path\n",
    "file_path = \"/work/Bachelor/sample_data/text.txt\"\n",
    "\n",
    "# Open the file and read its contents into a string\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    raw_text = file.read()  # Read all text data from the file\n",
    "\n",
    "# Step 1: Split the text into articles based on '@@' markers\n",
    "articles = raw_text.split('@@')[1:]  # Split the text by '@@' and ignore the first empty item\n",
    "\n",
    "# Lists to store extracted data\n",
    "text_ids = []  # Initialize a list to store article IDs\n",
    "clean_texts = []  # Initialize a list to store cleaned article texts\n",
    "\n",
    "# Step 2: Process each article\n",
    "for article in articles:  # Loop through each article in the list\n",
    "    # Extract article ID (the number right after @@)\n",
    "    article_id_match = re.match(r'(\\d+)', article)  # Match numbers at the beginning of the article\n",
    "    text_id = article_id_match.group(1) if article_id_match else None  # Extract ID if match found, else None\n",
    "\n",
    "    # Remove the ID and any leading characters (up to the first space)\n",
    "    cleaned_article = re.sub(r'^\\d+\\s*', '', article)  # Remove leading numbers and spaces\n",
    "\n",
    "    # Remove HTML-like tags (<h>, <p>, etc.)\n",
    "    cleaned_article = re.sub(r'<[^>]+>', '', cleaned_article).strip()  # Remove HTML tags and extra spaces\n",
    "\n",
    "    # Append extracted data to lists\n",
    "    text_ids.append(text_id)  # Add the ID to the text_ids list\n",
    "    clean_texts.append(cleaned_article)  # Add the cleaned text to the clean_texts list\n",
    "\n",
    "# Step 3: Create a DataFrame to store the structured data\n",
    "sample_text = pd.DataFrame({\n",
    "    'textID': text_ids,  # Column with article IDs\n",
    "    'text': clean_texts   # Column with cleaned article texts\n",
    "})\n",
    "\n",
    "# Display the DataFrame\n",
    "print(sample_text)  # Output the DataFrame to view structured data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8779bfa1-3005-4d89-9b4a-00513333fd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        textID  X.words        date country               source  \\\n",
      "0     18207168      397  13.01.2006      US               Kotaku   \n",
      "1     18207169      757  13.01.2006      US       Michigan Radio   \n",
      "2     18207170      755  13.01.2006      US  New York Daily News   \n",
      "3     18207172     1677  13.01.2006      US       OregonLive.com   \n",
      "4     18207174      794  13.01.2011      US         Ars Technica   \n",
      "...        ...      ...         ...     ...                  ...   \n",
      "2908  18262873      743  16.11.2019      GB             Redbrick   \n",
      "2909  18262874      301  16.11.2019      NG          360Nobs.com   \n",
      "2910  18262875      203  16.11.2019      NG             Goal.com   \n",
      "2911  18262876      270  16.11.2019      NG    Gistmaster (blog)   \n",
      "2912  18262878      305  16.11.2020      GH             GhanaWeb   \n",
      "\n",
      "                                                    url  \\\n",
      "0     http://kotaku.com/5973495/author-of-the-warrio...   \n",
      "1     http://michiganradio.org/post/thats-what-they-...   \n",
      "2     http://www.nydailynews.com/life-style/eats/bes...   \n",
      "3     http://www.oregonlive.com/performance/index.ss...   \n",
      "4     http://arstechnica.com/gadgets/2013/01/ask-ars...   \n",
      "...                                                 ...   \n",
      "2908  http://www.redbrick.me/comment/politics/us-ele...   \n",
      "2909  https://www.360nobs.com/2016/11/port-harcourt-...   \n",
      "2910  http://www.goal.com/en-ng/news/12132/fifa-wome...   \n",
      "2911  https://www.niyitabiti.net/2016/11/grace-omogu...   \n",
      "2912  http://www.ghanaweb.com/GhanaHomePage/NewsArch...   \n",
      "\n",
      "                                                  title  \\\n",
      "0     Author of The Warriors, Cult Film Adapted to H...   \n",
      "1     That's What They Say: Dialect Society chooses ...   \n",
      "2                           Best of New York: Croissant   \n",
      "3     Reflecting on a quarter-century of growth in P...   \n",
      "4     Ask Ars: Does Facebook auto-delete content aft...   \n",
      "...                                                 ...   \n",
      "2908   Trump: Is It The End of the World As We Know It?   \n",
      "2909  Port Harcourt Refinery To Commence Production ...   \n",
      "2910  Spain game will be tough,admits Falconets Chin...   \n",
      "2911  Grace Omogui, octogenarian mother of ex-FIRS b...   \n",
      "2912                Women march for peace in Cape Coast   \n",
      "\n",
      "                                                   text  \n",
      "0     That 's What They Say : Dialect Society choose...  \n",
      "1     A sublime croissant at French Tart in Grant Ci...  \n",
      "2     Reflecting on a quarter-century of growth in P...  \n",
      "3     Ask Ars : Does Facebook auto-delete content af...  \n",
      "4     NEW YORK -- An associate of a notorious Russia...  \n",
      "...                                                 ...  \n",
      "2908  Did you know that Prime Minister Narendra Modi...  \n",
      "2909  Council voted Tuesday to support a new $30 per...  \n",
      "2910  News Local  $5M funding boost for six projects...  \n",
      "2911  A closed-door council meeting that reversed th...  \n",
      "2912  ?  Burrows helps Canucks beat Rangers 5-3 to e...  \n",
      "\n",
      "[2913 rows x 8 columns]\n",
      "2913\n"
     ]
    }
   ],
   "source": [
    "# playground 0 merge\n",
    "\n",
    "# ensure both 'textID' columns have the same data type (convert to string)\n",
    "df_sources_fr.loc[:, 'textID'] = dropbox_sources_17_05_US['textID'].astype(str)\n",
    "sample_text.loc[:, 'textID'] = dropbox_text_17_05['textID'].astype(str)\n",
    "\n",
    "# merge the two DataFrames on 'textID'\n",
    "combined_articles = pd.merge(df_sources_fr, sample_text, on='textID', how='inner')\n",
    "\n",
    "# display\n",
    "print(combined_articles)\n",
    "print(len(combined_articles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7af077fe-4996-459e-851f-813fdeab1fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Number of articles after splitting: 2914\n",
      "Step 4: Number of rows in the DataFrame: 2914\n",
      "        textID                                               text\n",
      "0        11241  Sol Yurick , the writer whose 1965 novel \" The...\n",
      "1        11242  That 's What They Say : Dialect Society choose...\n",
      "2        11243  A sublime croissant at French Tart in Grant Ci...\n",
      "3        11244  Reflecting on a quarter-century of growth in P...\n",
      "4        21242  Ask Ars : Does Facebook auto-delete content af...\n",
      "...        ...                                                ...\n",
      "2909  15281244  Did you know that Prime Minister Narendra Modi...\n",
      "2910  15291240  Council voted Tuesday to support a new $30 per...\n",
      "2911  15291242  News Local  $5M funding boost for six projects...\n",
      "2912  15291243  A closed-door council meeting that reversed th...\n",
      "2913  15291244  ?  Burrows helps Canucks beat Rangers 5-3 to e...\n",
      "\n",
      "[2914 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# playground 1\n",
    "\n",
    "# Define the file path (you would adjust this to your actual file path)\n",
    "file_path = \"/work/Bachelor/sample_data/text.txt\"\n",
    "\n",
    "# Open the file and read its contents into a string\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    raw_text = file.read()\n",
    "\n",
    "# Step 1: Split the text into articles based on '@@' markers\n",
    "articles = raw_text.split('@@')[1:]  # Skip the first empty split\n",
    "print(f\"Step 1: Number of articles after splitting: {len(articles)}\")\n",
    "\n",
    "# Lists to store extracted data\n",
    "text_ids = []\n",
    "clean_texts = []\n",
    "\n",
    "# Step 2: Process each article\n",
    "for article in articles:\n",
    "    # Extract article ID (the number right after @@)\n",
    "    article_id_match = re.match(r'(\\d+)', article)\n",
    "    text_id = article_id_match.group(1) if article_id_match else None\n",
    "    \n",
    "    # Remove the ID and any leading characters (up to the first space)\n",
    "    cleaned_article = re.sub(r'^\\d+\\s*', '', article)\n",
    "\n",
    "    # Remove HTML-like tags (<h>, <p>, etc.)\n",
    "    cleaned_article = re.sub(r'<[^>]+>', '', cleaned_article).strip()\n",
    "\n",
    "    # Append extracted data to lists\n",
    "    text_ids.append(text_id)\n",
    "    clean_texts.append(cleaned_article)\n",
    "\n",
    "    # Print progress for each article processed\n",
    "    #print(f\"Processed article ID: {text_id}, Current number of articles: {len(text_ids)}\")\n",
    "\n",
    "# Step 3: Create a DataFrame to store the structured data\n",
    "df_text = pd.DataFrame({\n",
    "    'textID': text_ids,\n",
    "    'text': clean_texts\n",
    "})\n",
    "\n",
    "# Step 4: Print the final number of rows in the DataFrame\n",
    "print(f\"Step 4: Number of rows in the DataFrame: {df_text.shape[0]}\")\n",
    "\n",
    "# Display the DataFrame (optional)\n",
    "print(df_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b86433c0-b363-4b20-aab2-d400caaf3ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Number of articles after splitting: 2914\n",
      "Step 4: Number of rows in the DataFrame: 2914\n",
      "        textID                                               text\n",
      "0        11241  Sol Yurick , the writer whose 1965 novel \" The...\n",
      "1        11242  That 's What They Say : Dialect Society choose...\n",
      "2        11243  A sublime croissant at French Tart in Grant Ci...\n",
      "3        11244  Reflecting on a quarter-century of growth in P...\n",
      "4        21242  Ask Ars : Does Facebook auto-delete content af...\n",
      "...        ...                                                ...\n",
      "2909  15281244  Did you know that Prime Minister Narendra Modi...\n",
      "2910  15291240  Council voted Tuesday to support a new $30 per...\n",
      "2911  15291242  News Local  $5M funding boost for six projects...\n",
      "2912  15291243  A closed-door council meeting that reversed th...\n",
      "2913  15291244  ?  Burrows helps Canucks beat Rangers 5-3 to e...\n",
      "\n",
      "[2914 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# playground 2\n",
    "\n",
    "# Define the file path (you would adjust this to your actual file path)\n",
    "file_path = \"/work/Bachelor/sample_data/text.txt\"\n",
    "\n",
    "# Open the file and read its contents into a string\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    raw_text = file.read()\n",
    "\n",
    "# Step 1: Split the text using the pattern '@@' followed by digits\n",
    "# The pattern '@@\\d+' matches the '@@' followed by one or more digits\n",
    "articles = re.split(r'@@\\d+', raw_text)[1:]  # Skip the first empty split\n",
    "print(f\"Step 1: Number of articles after splitting: {len(articles)}\")\n",
    "\n",
    "# Lists to store extracted data\n",
    "text_ids = []\n",
    "clean_texts = []\n",
    "\n",
    "# Step 2: Process each article\n",
    "# Find all occurrences of '@@' followed by digits to extract IDs\n",
    "article_ids = re.findall(r'@@(\\d+)', raw_text)\n",
    "\n",
    "for i, article in enumerate(articles):\n",
    "    # Extract article ID from the pre-extracted article_ids list\n",
    "    text_id = article_ids[i] if i < len(article_ids) else None\n",
    "    \n",
    "    # Remove HTML-like tags (<h>, <p>, etc.)\n",
    "    cleaned_article = re.sub(r'<[^>]+>', '', article).strip()\n",
    "\n",
    "    # Append extracted data to lists\n",
    "    text_ids.append(text_id)\n",
    "    clean_texts.append(cleaned_article)\n",
    "\n",
    "    # Print progress for each article processed\n",
    "    #print(f\"Processed article ID: {text_id}, Current number of articles: {len(text_ids)}\")\n",
    "\n",
    "# Step 3: Create a DataFrame to store the structured data\n",
    "df_text = pd.DataFrame({\n",
    "    'textID': text_ids,\n",
    "    'text': clean_texts\n",
    "})\n",
    "\n",
    "# Step 4: Print the final number of rows in the DataFrame\n",
    "print(f\"Step 4: Number of rows in the DataFrame: {df_text.shape[0]}\")\n",
    "\n",
    "# Display the DataFrame (optional)\n",
    "print(df_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c17dc68-bc4f-4844-b48d-10076979169d",
   "metadata": {},
   "source": [
    "### compare rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a8d6039c-bcd2-496e-b6ef-c0caaa07b6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "textID                                               2911244\n",
      "X.words                                                  712\n",
      "date                                              14.11.2008\n",
      "country                                                   CA\n",
      "source                                         Globalnews.ca\n",
      "url        http://globalnews.ca/news/1661449/thousands-of...\n",
      "title      Thousands of Israeli Arabs protest fatal polic...\n",
      "Name: 1000, dtype: object\n",
      "textID                                              2911244\n",
      "text      What is this ?  WATCH ABOVE : Thousands of pro...\n",
      "Name: 1000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# source\n",
    "print(df_sources_fr.iloc[1000])\n",
    "\n",
    "# text\n",
    "print(df_text.iloc[1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e69227-207c-49d1-81f0-899e91351a11",
   "metadata": {},
   "source": [
    "#### Mmmmm it fits kind of, but it stops the further into the dataset we get"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2164d8c6-b2e8-431b-b5df-14f02f8f6d28",
   "metadata": {},
   "source": [
    "### Save df_text as csv to compare to sources.csv visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e69cba93-1239-4f75-bf6f-a8a4db3d074c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save text df as csv to compare with sources.csv\n",
    "\n",
    "# Define the file path where you want to save the CSV\n",
    "output_file_path = \"/work/Bachelor/sample_data/stopthenonsense/text1.csv\"\n",
    "\n",
    "# Save the filtered DataFrame as a CSV file\n",
    "df_text.to_csv(output_file_path, index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
