{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2766135f-bd17-4379-a22b-bcc860f332fa",
   "metadata": {},
   "source": [
    "# Purpose of notebook: playground for doing word embeddings\n",
    "\n",
    "# Where we at: BERT virker, SBERT vil ikke importeres. Er bange for conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34ebd09d-50b4-4abd-879a-17016c24e126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.46.2-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2 (from transformers)\n",
      "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.12/site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers)\n",
      "  Downloading tokenizers-0.20.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.12/site-packages (from transformers) (4.66.5)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.23.2->transformers)\n",
      "  Downloading fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\n",
      "Downloading transformers-4.46.2-py3-none-any.whl (10.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\n",
      "Downloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (796 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m796.9/796.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (434 kB)\n",
      "Downloading tokenizers-0.20.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Downloading fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "Installing collected packages: safetensors, regex, fsspec, filelock, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed filelock-3.16.1 fsspec-2024.10.0 huggingface-hub-0.26.2 regex-2024.11.6 safetensors-0.4.5 tokenizers-0.20.3 transformers-4.46.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting torch\n",
      "  Downloading torch-2.5.1-cp312-cp312-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.12/site-packages (from torch) (2024.10.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.1.0 (from torch)\n",
      "  Downloading triton-3.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch) (75.1.0)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading torch-2.5.1-cp312-cp312-manylinux1_x86_64.whl (906.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m128.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m129.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m113.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m109.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m131.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m97.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.6/209.6 MB\u001b[0m \u001b[31m102.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
      "Successfully installed mpmath-1.3.0 networkx-3.4.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 sympy-1.13.1 torch-2.5.1 triton-3.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting tf-keras\n",
      "  Downloading tf_keras-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting tensorflow<2.19,>=2.18 (from tf-keras)\n",
      "  Downloading tensorflow-2.18.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow<2.19,>=2.18->tf-keras)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow<2.19,>=2.18->tf-keras)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow<2.19,>=2.18->tf-keras)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow<2.19,>=2.18->tf-keras)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow<2.19,>=2.18->tf-keras)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow<2.19,>=2.18->tf-keras)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow<2.19,>=2.18->tf-keras)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (24.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow<2.19,>=2.18->tf-keras)\n",
      "  Downloading protobuf-5.28.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow<2.19,>=2.18->tf-keras)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.12/site-packages (from tensorflow<2.19,>=2.18->tf-keras) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow<2.19,>=2.18->tf-keras)\n",
      "  Downloading wrapt-1.16.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow<2.19,>=2.18->tf-keras)\n",
      "  Downloading grpcio-1.67.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow<2.19,>=2.18->tf-keras)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow<2.19,>=2.18->tf-keras)\n",
      "  Downloading keras-3.6.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting numpy<2.1.0,>=1.26.0 (from tensorflow<2.19,>=2.18->tf-keras)\n",
      "  Downloading numpy-2.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow<2.19,>=2.18->tf-keras)\n",
      "  Downloading h5py-3.12.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow<2.19,>=2.18->tf-keras)\n",
      "  Downloading ml_dtypes-0.4.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow<2.19,>=2.18->tf-keras) (0.44.0)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras)\n",
      "  Downloading optree-0.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (47 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow<2.19,>=2.18->tf-keras) (2024.8.30)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18->tf-keras) (3.0.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras) (2.18.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.19,>=2.18->tf-keras)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tf_keras-2.18.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow-2.18.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (615.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.5/615.5 MB\u001b[0m \u001b[31m87.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.67.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.12.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.6.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.4.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.2/19.2 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-5.28.3-cp38-abi3-manylinux2014_x86_64.whl (316 kB)\n",
      "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading wrapt-1.16.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (87 kB)\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.13.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (362 kB)\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorboard-data-server, protobuf, optree, opt-einsum, numpy, mdurl, markdown, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, ml-dtypes, markdown-it-py, h5py, rich, keras, tensorflow, tf-keras\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.3\n",
      "    Uninstalling numpy-2.1.3:\n",
      "      Successfully uninstalled numpy-2.1.3\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.67.1 h5py-3.12.1 keras-3.6.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.0.8 numpy-2.0.2 opt-einsum-3.4.0 optree-0.13.0 protobuf-5.28.3 rich-13.9.4 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 termcolor-2.5.0 tf-keras-2.18.0 werkzeug-3.1.3 wrapt-1.16.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.14.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: numpy<2.3,>=1.23.5 in /opt/conda/lib/python3.12/site-packages (from scipy) (2.0.2)\n",
      "Downloading scipy-1.14.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: scipy\n",
      "Successfully installed scipy-1.14.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: tensorflow in /opt/conda/lib/python3.12/site-packages (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.12/site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (5.28.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (1.67.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /opt/conda/lib/python3.12/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in /opt/conda/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /opt/conda/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.13.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# libraries\n",
    "\n",
    "# install\n",
    "%pip install transformers\n",
    "%pip install torch\n",
    "%pip install tf-keras # install this because keras needs to work on a previous version of python\n",
    "%pip install scipy\n",
    "%pip install pandas\n",
    "%pip install tensorflow\n",
    "%pip install -U sentence-transformers\n",
    "%pip install numpy\n",
    "\n",
    "\n",
    "\n",
    "# import\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "from scipy.spatial.distance import cosine\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46971c74-da0f-4852-b1b4-214464328364",
   "metadata": {},
   "source": [
    "## test playground for 1 sentence with BERT (bert-base-uncased) - works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "645d783c-1758-40ce-8d35-c5fb60d2e8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac0988d560ef4f6c9cccd71893435be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7b454ce6af948638791fb84aa976078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca110a0467dd42b7b88c10bd06d1de31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db84421a134144e68cc97d6f44ff729d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a959561b4da4d3a9808b7d4e8c08fe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# load pretrained tokenizer and model (uncased means it converts all text to lowercase and removes any accent markers before tokenization)\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = TFBertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a3675f9-9312-4df2-868e-50b14d46a225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize the input text and convert it into token IDs and attention masks (Token IDs represent the input tokens in numeric form that BERT can process. Attention Masks tell the model which tokens are real words and which are padding (for aligning input lengths))\n",
    "text = \"Abortion is murder of innocent babies.\"\n",
    "encoded_input = tokenizer(text, return_tensors='tf') # This tells the tokenizer to return the tokenized output as TensorFlow tensors (which are the required format for TFBertModel). So the returned encoded_input contains input_ids: Numerical IDs for the tokens and attention_mask: A binary mask indicating which positions are padding (0) or actual data (1) (this is important when dealing with more text where sentences or document differ in length)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84663cba-5338-4cbe-944f-716a28b697f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passing the Tokenized Input Through the BERT Model\n",
    "output = model(encoded_input)\n",
    "#output # makes no sense to the human eye but I think it works as it should"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e1c421-d101-445c-b2df-b8e6b34b6ba4",
   "metadata": {},
   "source": [
    "## test playground for 2 sentences text embedding and semantic similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b8c826-9cf1-4c8e-8393-4a3bbed81dd0",
   "metadata": {},
   "source": [
    "#### Word level - works not very well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0cc91c57-d9aa-4bdb-af9d-84d64be59de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Similarity for 'abortion': 0.9759\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = TFBertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Function to get contextual embedding for a specific word\n",
    "def get_word_embedding(text, target_word):\n",
    "    encoded_input = tokenizer(text, return_tensors='tf', padding=True, truncation=True)\n",
    "    outputs = model(encoded_input)\n",
    "    \n",
    "    # Extract token embeddings\n",
    "    token_embeddings = outputs.last_hidden_state  # [batch_size, seq_len, hidden_dim]\n",
    "    \n",
    "    # Find the token index for the target word\n",
    "    token_ids = encoded_input['input_ids'][0]\n",
    "    target_word_id = tokenizer.convert_tokens_to_ids(target_word)\n",
    "    word_indices = tf.where(token_ids == target_word_id)\n",
    "    \n",
    "    if len(word_indices) == 0:\n",
    "        print(f\"'{target_word}' not found in the sentence.\")\n",
    "        return None\n",
    "    \n",
    "    # Average embeddings if the word appears multiple times\n",
    "    word_embedding = tf.reduce_mean(tf.gather(token_embeddings[0], word_indices[:, 0]), axis=0)\n",
    "    return word_embedding\n",
    "\n",
    "# First sentence\n",
    "sentence1 = \"Abortion is murder of babies.\"\n",
    "embedding1 = get_word_embedding(sentence1, 'abortion')\n",
    "\n",
    "# Second sentence\n",
    "sentence2 = \"Abortion is a safe medical procedure for women.\"\n",
    "embedding2 = get_word_embedding(sentence2, 'abortion')\n",
    "\n",
    "# Check if both embeddings are valid\n",
    "if embedding1 is not None and embedding2 is not None:\n",
    "    # Calculate cosine similarity\n",
    "    similarity_score = 1 - cosine(embedding1.numpy(), embedding2.numpy())\n",
    "    print(f\"Semantic Similarity for 'abortion': {similarity_score:.4f}\")\n",
    "else:\n",
    "    print(\"Failed to compute similarity due to missing embeddings.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85a3c8d7-e706-4f26-88f9-d8c76e618aae",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_word_embedding' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Sentence 1\u001b[39;00m\n\u001b[1;32m      9\u001b[0m sentence1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAbortion is reproductive health care.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 10\u001b[0m embedding1 \u001b[38;5;241m=\u001b[39m \u001b[43mget_word_embedding\u001b[49m(sentence1, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabortion\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Sentence 2\u001b[39;00m\n\u001b[1;32m     13\u001b[0m sentence2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAbortion is a safe medical procedure for women.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_word_embedding' is not defined"
     ]
    }
   ],
   "source": [
    "def get_sentence_embedding(text):\n",
    "    encoded_input = tokenizer(text, return_tensors='tf', padding=True, truncation=True)\n",
    "    output = model(encoded_input)\n",
    "    # Use [CLS] token embedding for the entire sentence\n",
    "    cls_embedding = output.last_hidden_state[:, 0, :]  # [CLS] token is at index 0\n",
    "    return cls_embedding\n",
    "\n",
    "# Sentence 1\n",
    "sentence1 = \"Abortion is reproductive health care.\"\n",
    "embedding1 = get_word_embedding(sentence1, 'abortion')\n",
    "\n",
    "# Sentence 2\n",
    "sentence2 = \"Abortion is a safe medical procedure for women.\"\n",
    "embedding2 = get_word_embedding(sentence2, 'abortion')\n",
    "\n",
    "# Compute embeddings for entire sentences\n",
    "embedding1 = get_sentence_embedding(sentence1)\n",
    "embedding2 = get_sentence_embedding(sentence2)\n",
    "\n",
    "# Compute cosine similarity\n",
    "similarity_score = 1 - cosine(embedding1.numpy(), embedding2.numpy())\n",
    "print(f\"Semantic Similarity for entire sentences: {similarity_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d30464-e131-48af-953f-e339d0577b70",
   "metadata": {},
   "source": [
    "### SentenceTransformer model - maybe not appropriate for here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "23e8d412-cacb-4c00-9a2d-efe10d33051a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Similarity using SBERT: 0.8555\n"
     ]
    }
   ],
   "source": [
    "# SBERT\n",
    "\n",
    "# Load pretrained SBERT model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # Lightweight and effective model\n",
    "\n",
    "# Sentences to compare\n",
    "sentence1 = \"Abortion is reproductive health care.\"\n",
    "sentence2 = \"Abortion is a human health care right.\"\n",
    "\n",
    "# Get sentence embeddings\n",
    "embedding1 = model.encode(sentence1)\n",
    "embedding2 = model.encode(sentence2)\n",
    "\n",
    "# Compute cosine similarity\n",
    "similarity_score = 1 - cosine(embedding1, embedding2)\n",
    "print(f\"Semantic Similarity using SBERT: {similarity_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b423988-5a33-4457-b8b3-8501bcc3500a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 384)\n",
      "tensor([[1.0000, 0.7141, 0.6337],\n",
      "        [0.7141, 1.0000, 0.6166],\n",
      "        [0.6337, 0.6166, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "# Load pretrained SBERT model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # Lightweight and effective model\n",
    "\n",
    "# The sentences to encode\n",
    "sentences = [\n",
    "    \"Abortion is a human right\",\n",
    "    \"Abortion is murder on innocent babies\",\n",
    "    \"Abortion should be banned in all states\",\n",
    "]\n",
    "\n",
    "# Calculate embeddings by calling model.encode()\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings.shape)\n",
    "\n",
    "# Calculate the embedding similarities\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd03264d-b91e-4931-b5a4-c2b5a5d4ded9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# List of sentences to be processed\n",
    "sentences = [\n",
    "    \"Three years later, the coffin was still full of Jello.\",\n",
    "    \"The fish dreamed of escaping the fishbowl and into the toilet where he saw his friend go.\",\n",
    "    \"The person box was packed with jelly many dozens of months later.\",\n",
    "    \"He found a leprechaun in his walnut shell.\"\n",
    "]\n",
    "\n",
    "# Initializing the Sentence Transformer model using BERT with mean-tokens pooling\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "# Encoding the sentences to obtain their embeddings\n",
    "sentence_embeddings = model.encode(sentences)\n",
    "\n",
    "# Calculating the cosine similarity between the first sentence embedding and the rest of the embeddings\n",
    "# The result will be a list of similarity scores between the first sentence and each of the other sentences\n",
    "similarity_scores = cosine_similarity([sentence_embeddings[0]], sentence_embeddings[1:])\n",
    "similarity_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145904e9-a821-4b61-97c8-2639d796ec92",
   "metadata": {},
   "source": [
    "### Token-based SentenceTransformer model - verdict tbd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9797529d-e361-4906-9042-5a3cf13207b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "11328 is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m     word_idx \u001b[38;5;241m=\u001b[39m tokens[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;241m.\u001b[39mindex(model\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mconvert_tokens_to_ids(target_word))\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m token_embeddings[\u001b[38;5;241m0\u001b[39m][word_idx]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m---> 23\u001b[0m embedding1 \u001b[38;5;241m=\u001b[39m \u001b[43mget_token_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_embeddings1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mabortion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m embedding2 \u001b[38;5;241m=\u001b[39m get_token_embedding(tokens2, token_embeddings2, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabortion\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Calculate cosine similarity\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[18], line 20\u001b[0m, in \u001b[0;36mget_token_embedding\u001b[0;34m(tokens, token_embeddings, target_word)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_token_embedding\u001b[39m(tokens, token_embeddings, target_word):\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# Identify the token index for the word 'abortion'\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m     word_idx \u001b[38;5;241m=\u001b[39m \u001b[43mtokens\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_tokens_to_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_word\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m token_embeddings[\u001b[38;5;241m0\u001b[39m][word_idx]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[0;31mValueError\u001b[0m: 11328 is not in list"
     ]
    }
   ],
   "source": [
    "# Load a Token-Based SentenceTransformer model\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')  # Example model\n",
    "\n",
    "# Define the sentences\n",
    "sentence1 = \"Abortion is a controversial topic in politics.\"\n",
    "sentence2 = \"Abortion is a medical procedure.\"\n",
    "\n",
    "# Tokenize and encode the sentences\n",
    "tokens1 = model.tokenize(sentence1)\n",
    "tokens2 = model.tokenize(sentence2)\n",
    "\n",
    "# Get token embeddings for each sentence\n",
    "with torch.no_grad():\n",
    "    token_embeddings1 = model(tokens1)['token_embeddings']\n",
    "    token_embeddings2 = model(tokens2)['token_embeddings']\n",
    "\n",
    "# Find token embeddings for the word \"abortion\"\n",
    "def get_token_embedding(tokens, token_embeddings, target_word):\n",
    "    # Identify the token index for the word 'abortion'\n",
    "    word_idx = tokens['input_ids'][0].tolist().index(model.tokenizer.convert_tokens_to_ids(target_word))\n",
    "    return token_embeddings[0][word_idx].detach().numpy()\n",
    "\n",
    "embedding1 = get_token_embedding(tokens1, token_embeddings1, 'abortion')\n",
    "embedding2 = get_token_embedding(tokens2, token_embeddings2, 'abortion')\n",
    "\n",
    "# Calculate cosine similarity\n",
    "similarity = 1 - cosine(embedding1, embedding2)\n",
    "print(f\"Cosine similarity for 'abortion': {similarity:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba5ee678-35ab-42f2-9b12-9b14167428ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'abortion' or its subwords not found in the tokenized sentence.\n",
      "'abortion' or its subwords not found in the tokenized sentence.\n"
     ]
    }
   ],
   "source": [
    "# Load a Token-Based SentenceTransformer model\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "# Define the sentences\n",
    "sentence1 = \"Abortion is a controversial topic in politics.\"\n",
    "sentence2 = \"Abortion is a medical procedure.\"\n",
    "\n",
    "# Tokenize and encode the sentences\n",
    "tokens1 = model.tokenize(sentence1)\n",
    "tokens2 = model.tokenize(sentence2)\n",
    "\n",
    "# Get token embeddings for each sentence\n",
    "with torch.no_grad():\n",
    "    token_embeddings1 = model(tokens1)['token_embeddings']\n",
    "    token_embeddings2 = model(tokens2)['token_embeddings']\n",
    "\n",
    "# Updated function to handle subword tokenization\n",
    "def get_token_embedding(tokens, token_embeddings, target_word):\n",
    "    # Get the tokenized word pieces for the target word\n",
    "    target_word_id = model.tokenizer.convert_tokens_to_ids(target_word)\n",
    "    \n",
    "    # Find all token indices for subword parts of the target word\n",
    "    word_indices = [\n",
    "        i for i, token_id in enumerate(tokens['input_ids'][0].tolist())\n",
    "        if token_id == target_word_id\n",
    "    ]\n",
    "\n",
    "    if not word_indices:\n",
    "        print(f\"'{target_word}' or its subwords not found in the tokenized sentence.\")\n",
    "        return None\n",
    "    \n",
    "    # Average embeddings if multiple subwords\n",
    "    word_embedding = token_embeddings[0][word_indices].mean(dim=0).detach().numpy()\n",
    "    return word_embedding\n",
    "\n",
    "# Find token embeddings for the word \"abortion\"\n",
    "embedding1 = get_token_embedding(tokens1, token_embeddings1, 'abortion')\n",
    "embedding2 = get_token_embedding(tokens2, token_embeddings2, 'abortion')\n",
    "\n",
    "# Calculate cosine similarity\n",
    "if embedding1 is not None and embedding2 is not None:\n",
    "    similarity = 1 - cosine(embedding1, embedding2)\n",
    "    print(f\"Cosine similarity for 'abortion': {similarity:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6cd8566c-d91e-4908-b7e6-2b656f727b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'abortion' or its subwords not found.\n",
      "'abortion' or its subwords not found.\n"
     ]
    }
   ],
   "source": [
    "# Load a Token-Based SentenceTransformer model\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "# Define the sentences\n",
    "sentence1 = \"Abortion is a controversial topic in politics.\"\n",
    "sentence2 = \"Abortion is a medical procedure.\"\n",
    "\n",
    "# Tokenize and encode the sentences\n",
    "tokens1 = model.tokenize(sentence1)\n",
    "tokens2 = model.tokenize(sentence2)\n",
    "\n",
    "# Get token embeddings for each sentence\n",
    "with torch.no_grad():\n",
    "    token_embeddings1 = model(tokens1)['token_embeddings']\n",
    "    token_embeddings2 = model(tokens2)['token_embeddings']\n",
    "\n",
    "# Updated function to handle subword tokenization\n",
    "def get_token_embedding(tokens, token_embeddings, target_word):\n",
    "    subword_ids = model.tokenizer(target_word, add_special_tokens=False)['input_ids']\n",
    "    sentence_ids = tokens['input_ids'][0].tolist()\n",
    "    \n",
    "    for i in range(len(sentence_ids) - len(subword_ids) + 1):\n",
    "        if sentence_ids[i:i + len(subword_ids)] == subword_ids:\n",
    "            word_embedding = token_embeddings[0][i:i + len(subword_ids)].mean(dim=0).detach().numpy()\n",
    "            return word_embedding\n",
    "    \n",
    "    print(f\"'{target_word}' or its subwords not found.\")\n",
    "    return None\n",
    "\n",
    "# Find token embeddings for the word \"abortion\"\n",
    "embedding1 = get_token_embedding(tokens1, token_embeddings1, 'abortion')\n",
    "embedding2 = get_token_embedding(tokens2, token_embeddings2, 'abortion')\n",
    "\n",
    "# Calculate cosine similarity\n",
    "if embedding1 is not None and embedding2 is not None:\n",
    "    similarity = 1 - cosine(embedding1, embedding2)\n",
    "    print(f\"Cosine similarity for 'abortion': {similarity:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a7848f7-8991-420e-84cc-d0580336de73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33088905, 0.72192585, 0.5548365 ]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "176327da-ed88-4ede-adbc-f69c33474e6d",
   "metadata": {},
   "source": [
    "## Keyword specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f323d6d-f071-46fc-86d6-803eb77072d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (2.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c2179919-9c45-4ad9-b7da-26968703ddea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'abortion' and Article 1: 0.4611\n",
      "Similarity between 'abortion' and Article 2: 0.5539\n",
      "Similarity between 'abortion' and Article 3: 0.5868\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import numpy as np\n",
    "\n",
    "# Step 1: Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to get embeddings\n",
    "def get_embedding(text):\n",
    "    tokens = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        output = model(**tokens)\n",
    "    # Take the mean of the last hidden state (average pooling)\n",
    "    embedding = output.last_hidden_state.mean(dim=1).squeeze()\n",
    "    return embedding.numpy()\n",
    "\n",
    "# Step 2: Embed articles\n",
    "articles = [\n",
    "    \"Abortion is a highly controversial topic in today's society.\",\n",
    "    \"Healthcare providers offer abortion services to women in need.\",\n",
    "    \"Some laws heavily restrict abortion access.\"\n",
    "]\n",
    "\n",
    "article_embeddings = [get_embedding(article) for article in articles]\n",
    "\n",
    "# Step 3: Embed the keyword\n",
    "keyword = \"abortion\"\n",
    "keyword_embedding = get_embedding(keyword).reshape(1, -1)\n",
    "\n",
    "# Step 4: Calculate semantic similarity\n",
    "similarities = [cosine_similarity(keyword_embedding, embedding.reshape(1, -1))[0][0] for embedding in article_embeddings]\n",
    "\n",
    "# Step 5: Display results\n",
    "for i, similarity in enumerate(similarities):\n",
    "    print(f\"Similarity between '{keyword}' and Article {i+1}: {similarity:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ed2aa90-d5af-4e0d-a22c-16169b9e388e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN Similarities:\n",
      "Article 1: 0.4611\n",
      "Article 2: 0.5539\n",
      "\n",
      "Fox News Similarities:\n",
      "Article 1: 0.5868\n",
      "Article 2: 0.6444\n",
      "\n",
      "Average Similarity for CNN: 0.5075\n",
      "Average Similarity for Fox News: 0.6156\n"
     ]
    }
   ],
   "source": [
    "# with CNN and Fox articles\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to get embeddings\n",
    "def get_embedding(text):\n",
    "    tokens = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        output = model(**tokens)\n",
    "    embedding = output.last_hidden_state.mean(dim=1).squeeze()\n",
    "    return embedding.numpy()\n",
    "\n",
    "# CNN and Fox News articles\n",
    "cnn_articles = [\n",
    "    \"Abortion is a highly controversial topic in today's society.\",\n",
    "    \"Healthcare providers offer abortion services to women in need.\"\n",
    "]\n",
    "\n",
    "fox_articles = [\n",
    "    \"Some laws heavily restrict abortion access.\",\n",
    "    \"Abortion is banned many places.\"\n",
    "]\n",
    "\n",
    "# Embed articles\n",
    "cnn_embeddings = [get_embedding(article) for article in cnn_articles]\n",
    "fox_embeddings = [get_embedding(article) for article in fox_articles]\n",
    "\n",
    "# Embed the keyword\n",
    "keyword = \"abortion\"\n",
    "keyword_embedding = get_embedding(keyword).reshape(1, -1)\n",
    "\n",
    "# Calculate semantic similarity for each group\n",
    "cnn_similarities = [cosine_similarity(keyword_embedding, embedding.reshape(1, -1))[0][0] for embedding in cnn_embeddings]\n",
    "fox_similarities = [cosine_similarity(keyword_embedding, embedding.reshape(1, -1))[0][0] for embedding in fox_embeddings]\n",
    "\n",
    "# Display results\n",
    "print(\"CNN Similarities:\")\n",
    "for i, similarity in enumerate(cnn_similarities):\n",
    "    print(f\"Article {i+1}: {similarity:.4f}\")\n",
    "\n",
    "print(\"\\nFox News Similarities:\")\n",
    "for i, similarity in enumerate(fox_similarities):\n",
    "    print(f\"Article {i+1}: {similarity:.4f}\")\n",
    "\n",
    "# Calculate average similarity for each group\n",
    "avg_cnn_similarity = np.mean(cnn_similarities)\n",
    "avg_fox_similarity = np.mean(fox_similarities)\n",
    "\n",
    "print(f\"\\nAverage Similarity for CNN: {avg_cnn_similarity:.4f}\")\n",
    "print(f\"Average Similarity for Fox News: {avg_fox_similarity:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c599744a-249b-41f8-8caa-21557330c305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairwise Similarities between CNN and Fox News contextual embeddings for 'abortion':\n",
      "Pair 1: 0.9636\n",
      "Pair 2: 0.2296\n",
      "Pair 3: 0.9687\n",
      "Pair 4: 0.1585\n",
      "\n",
      "Average Similarity between CNN and Fox News usage of 'abortion': 0.5801\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to get contextual embedding for a specific word in a text\n",
    "def get_contextual_embedding(text, keyword):\n",
    "    tokens = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        output = model(**tokens)\n",
    "    # Get the token index for the keyword\n",
    "    keyword_index = (tokens.input_ids == tokenizer.encode(keyword, add_special_tokens=False)[0]).nonzero(as_tuple=True)[1]\n",
    "    # Extract the embedding for the keyword in its context\n",
    "    keyword_embedding = output.last_hidden_state[0, keyword_index, :].mean(dim=0)\n",
    "    return keyword_embedding.numpy()\n",
    "\n",
    "# CNN and Fox News articles\n",
    "cnn_articles = [\n",
    "    \"Abortion is murder\",\n",
    "    \"Abortion is health care\"\n",
    "]\n",
    "\n",
    "fox_articles = [\n",
    "    \"Abortion is killing babies\",\n",
    "    \"Healthcare providers offer abortion services to women in need.\"\n",
    "]\n",
    "\n",
    "# Get contextual embeddings for 'abortion' in each article\n",
    "cnn_contextual_embeddings = [get_contextual_embedding(article, 'abortion') for article in cnn_articles]\n",
    "fox_contextual_embeddings = [get_contextual_embedding(article, 'abortion') for article in fox_articles]\n",
    "\n",
    "# Calculate pairwise similarities between CNN and Fox News contextual embeddings\n",
    "similarities = []\n",
    "for cnn_embedding in cnn_contextual_embeddings:\n",
    "    for fox_embedding in fox_contextual_embeddings:\n",
    "        similarity = cosine_similarity(cnn_embedding.reshape(1, -1), fox_embedding.reshape(1, -1))[0][0]\n",
    "        similarities.append(similarity)\n",
    "\n",
    "# Display results\n",
    "print(\"Pairwise Similarities between CNN and Fox News contextual embeddings for 'abortion':\")\n",
    "for i, similarity in enumerate(similarities):\n",
    "    print(f\"Pair {i+1}: {similarity:.4f}\")\n",
    "\n",
    "# Average similarity across CNN vs Fox contexts\n",
    "avg_similarity = np.mean(similarities)\n",
    "print(f\"\\nAverage Similarity between CNN and Fox News usage of 'abortion': {avg_similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "493e3aca-4e3e-4d18-b210-0306bb1308a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between CNN and Fox News aggregated usage of 'abortion': 0.9342\n"
     ]
    }
   ],
   "source": [
    "# PYTORCH\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to get contextual embedding for a specific word in a text\n",
    "def get_contextual_embedding(text, keyword):\n",
    "    tokens = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        output = model(**tokens)\n",
    "    # Get the token index for the keyword\n",
    "    keyword_index = (tokens.input_ids == tokenizer.encode(keyword, add_special_tokens=False)[0]).nonzero(as_tuple=True)[1]\n",
    "    # Extract the embedding for the keyword in its context\n",
    "    keyword_embedding = output.last_hidden_state[0, keyword_index, :].mean(dim=0)\n",
    "    return keyword_embedding.numpy()\n",
    "\n",
    "# CNN and Fox News articles\n",
    "cnn_articles = [\n",
    "    \"Abortion is murder.\",\n",
    "    \"Healthcare providers should not offer abortion services to women in need.\"\n",
    "]\n",
    "\n",
    "fox_articles = [\n",
    "    \"Some laws heavily restrict abortion access, and this is taking away women's rights.\",\n",
    "    \"Abortion should be legal in all states.\"\n",
    "]\n",
    "\n",
    "# Get contextual embeddings for 'abortion' in each article\n",
    "cnn_contextual_embeddings = [get_contextual_embedding(article, 'abortion') for article in cnn_articles]\n",
    "fox_contextual_embeddings = [get_contextual_embedding(article, 'abortion') for article in fox_articles]\n",
    "\n",
    "# Step 1: Aggregate embeddings within each source\n",
    "cnn_aggregated_embedding = np.mean(cnn_contextual_embeddings, axis=0)\n",
    "fox_aggregated_embedding = np.mean(fox_contextual_embeddings, axis=0)\n",
    "\n",
    "# Step 2: Compare aggregated embeddings between CNN and Fox News\n",
    "similarity_between_sources = cosine_similarity(\n",
    "    cnn_aggregated_embedding.reshape(1, -1), \n",
    "    fox_aggregated_embedding.reshape(1, -1)\n",
    ")[0][0]\n",
    "\n",
    "# Display results\n",
    "print(f\"Similarity between CNN and Fox News aggregated usage of 'abortion': {similarity_between_sources:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72118be6-d6fa-40ab-80d3-32762861d7fc",
   "metadata": {},
   "source": [
    "### Using pytorch or tensorflow for semantic similarity gives the exact same result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3e679a88-d019-4d83-9f1d-e0e377b9306e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "no_gradient() missing 1 required positional argument: 'op_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 31\u001b[0m\n\u001b[1;32m     25\u001b[0m fox_articles \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSome laws heavily restrict abortion access, and this is taking away women\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms rights.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAbortion should be legal in all states.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     28\u001b[0m ]\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Get contextual embeddings for 'abortion' in each article\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m cnn_contextual_embeddings \u001b[38;5;241m=\u001b[39m [\u001b[43mget_contextual_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43marticle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mabortion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m article \u001b[38;5;129;01min\u001b[39;00m cnn_articles]\n\u001b[1;32m     32\u001b[0m fox_contextual_embeddings \u001b[38;5;241m=\u001b[39m [get_contextual_embedding(article, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabortion\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m article \u001b[38;5;129;01min\u001b[39;00m fox_articles]\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Step 1: Aggregate embeddings within each source\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[40], line 10\u001b[0m, in \u001b[0;36mget_contextual_embedding\u001b[0;34m(text, keyword)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_contextual_embedding\u001b[39m(text, keyword):\n\u001b[1;32m      9\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m tokenizer(text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_gradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     11\u001b[0m         output \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtokens)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# Find the token index of the keyword\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: no_gradient() missing 1 required positional argument: 'op_type'"
     ]
    }
   ],
   "source": [
    "# TENSORFLOW\n",
    "\n",
    "# Load pre-trained TensorFlow BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to get contextual embedding for a specific word in a text\n",
    "def get_contextual_embedding(text, keyword):\n",
    "    tokens = tokenizer(text, return_tensors='tf', padding=True, truncation=True, max_length=512)\n",
    "    with tf.no_gradient():\n",
    "        output = model(**tokens)\n",
    "    # Find the token index of the keyword\n",
    "    keyword_id = tokenizer.encode(keyword, add_special_tokens=False)[0]\n",
    "    keyword_index = tf.where(tokens.input_ids == keyword_id)[0][1]  # First occurrence index\n",
    "    # Extract contextual embedding\n",
    "    keyword_embedding = tf.reduce_mean(output.last_hidden_state[:, keyword_index, :], axis=1)\n",
    "    return keyword_embedding.numpy()\n",
    "\n",
    "# CNN and Fox News articles\n",
    "cnn_articles = [\n",
    "    \"Abortion is murder.\",\n",
    "    \"Healthcare providers should not offer abortion services to women in need.\"\n",
    "]\n",
    "\n",
    "fox_articles = [\n",
    "    \"Some laws heavily restrict abortion access, and this is taking away women's rights.\",\n",
    "    \"Abortion should be legal in all states.\"\n",
    "]\n",
    "\n",
    "# Get contextual embeddings for 'abortion' in each article\n",
    "cnn_contextual_embeddings = [get_contextual_embedding(article, 'abortion') for article in cnn_articles]\n",
    "fox_contextual_embeddings = [get_contextual_embedding(article, 'abortion') for article in fox_articles]\n",
    "\n",
    "# Step 1: Aggregate embeddings within each source\n",
    "cnn_aggregated_embedding = np.mean(cnn_contextual_embeddings, axis=0)\n",
    "fox_aggregated_embedding = np.mean(fox_contextual_embeddings, axis=0)\n",
    "\n",
    "# Step 2: Compare aggregated embeddings between CNN and Fox News\n",
    "similarity_between_sources = cosine_similarity(\n",
    "    cnn_aggregated_embedding.reshape(1, -1), \n",
    "    fox_aggregated_embedding.reshape(1, -1)\n",
    ")[0][0]\n",
    "\n",
    "# Display results\n",
    "print(f\"Similarity between CNN and Fox News aggregated usage of 'abortion': {similarity_between_sources:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d655ed54-1c46-482b-825e-df600a858109",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between CNN and Fox News aggregated usage of 'abortion': 0.9342\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained TensorFlow BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to get contextual embedding for a specific word in a text\n",
    "def get_contextual_embedding(text, keyword):\n",
    "    tokens = tokenizer(text, return_tensors='tf', padding=True, truncation=True, max_length=512)\n",
    "    output = model(**tokens)\n",
    "    \n",
    "    # Find the token index of the keyword\n",
    "    keyword_id = tokenizer.encode(keyword, add_special_tokens=False)[0]\n",
    "    keyword_index = tf.where(tokens.input_ids == keyword_id)[0][1]  # First occurrence index\n",
    "    \n",
    "    # Extract contextual embedding for the keyword\n",
    "    keyword_embedding = tf.reduce_mean(output.last_hidden_state[:, keyword_index, :], axis=0)\n",
    "    return keyword_embedding.numpy()\n",
    "\n",
    "# CNN and Fox News articles\n",
    "cnn_articles = [\n",
    "    \"Abortion is murder.\",\n",
    "    \"Healthcare providers should not offer abortion services to women in need.\"\n",
    "]\n",
    "\n",
    "fox_articles = [\n",
    "    \"Some laws heavily restrict abortion access, and this is taking away women's rights.\",\n",
    "    \"Abortion should be legal in all states.\"\n",
    "]\n",
    "\n",
    "# Get contextual embeddings for 'abortion' in each article\n",
    "cnn_contextual_embeddings = [get_contextual_embedding(article, 'abortion') for article in cnn_articles]\n",
    "fox_contextual_embeddings = [get_contextual_embedding(article, 'abortion') for article in fox_articles]\n",
    "\n",
    "# Step 1: Aggregate embeddings within each source\n",
    "cnn_aggregated_embedding = np.mean(cnn_contextual_embeddings, axis=0)\n",
    "fox_aggregated_embedding = np.mean(fox_contextual_embeddings, axis=0)\n",
    "\n",
    "# Step 2: Compare aggregated embeddings between CNN and Fox News\n",
    "similarity_between_sources = cosine_similarity(\n",
    "    cnn_aggregated_embedding.reshape(1, -1), \n",
    "    fox_aggregated_embedding.reshape(1, -1)\n",
    ")[0][0]\n",
    "\n",
    "# Display results\n",
    "print(f\"Similarity between CNN and Fox News aggregated usage of 'abortion': {similarity_between_sources:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011b6a6a-9bc2-4736-b224-0e601be9c5fa",
   "metadata": {},
   "source": [
    "## trying to do **semantic polarity** like Ding et al. (2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "de57d79c-3e00-4f64-96d8-0d45eb788641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semantic Polarity (SP) between CNN and Fox News for 'abortion': 0.4481\n"
     ]
    }
   ],
   "source": [
    "# using pytorch not tensorflow\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to get contextual embedding for a specific word in a text\n",
    "def get_contextual_embeddings(texts, keyword):\n",
    "    embeddings = []\n",
    "    for text in texts:\n",
    "        tokens = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "        with torch.no_grad():\n",
    "            output = model(**tokens)\n",
    "        # Get the token index for the keyword\n",
    "        keyword_id = tokenizer.encode(keyword, add_special_tokens=False)[0]\n",
    "        keyword_index = (tokens.input_ids == keyword_id).nonzero(as_tuple=True)[1]\n",
    "        \n",
    "        if len(keyword_index) > 0:  # Only if the keyword exists in the text\n",
    "            keyword_embedding = output.last_hidden_state[0, keyword_index, :].mean(dim=0)\n",
    "            embeddings.append(keyword_embedding.numpy())\n",
    "    return embeddings\n",
    "\n",
    "# CNN and Fox News articles\n",
    "cnn_articles = [\n",
    "    \"Abortion is murder.\",\n",
    "    \"Healthcare providers should not offer abortion services to women in need.\"\n",
    "]\n",
    "\n",
    "fox_articles = [\n",
    "    \"Some laws heavily restrict abortion access, and this is taking away women's rights.\",\n",
    "    \"Abortion should be legal in all states.\"\n",
    "]\n",
    "\n",
    "# Get contextual embeddings for 'abortion' from CNN and Fox News\n",
    "cnn_embeddings = get_contextual_embeddings(cnn_articles, 'abortion')\n",
    "fox_embeddings = get_contextual_embeddings(fox_articles, 'abortion')\n",
    "\n",
    "# Compute Semantic Polarity (SP) between CNN and Fox News\n",
    "def compute_semantic_polarity(embeddings1, embeddings2):\n",
    "    total_distance = 0\n",
    "    count = 0\n",
    "    for emb1 in embeddings1:\n",
    "        for emb2 in embeddings2:\n",
    "            distance = 1 - cosine_similarity(emb1.reshape(1, -1), emb2.reshape(1, -1))[0][0]\n",
    "            total_distance += distance\n",
    "            count += 1\n",
    "    return total_distance / count if count > 0 else 0\n",
    "\n",
    "semantic_polarity = compute_semantic_polarity(cnn_embeddings, fox_embeddings)\n",
    "\n",
    "# Display results\n",
    "print(f\"Semantic Polarity (SP) between CNN and Fox News for 'abortion': {semantic_polarity:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b71b7f-0c59-4ba9-955e-7264241280f7",
   "metadata": {},
   "source": [
    "### Code works, might work... Testing over time to see if that works and to see how good this whole thing is at measuring semantic polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5f17a1-8bd7-4aa3-b133-1626ea32b34e",
   "metadata": {},
   "source": [
    "#### Make test dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fb7d44a3-b267-4776-9b06-281edee207bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>words</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>source</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12345678</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-11-03</td>\n",
       "      <td>US</td>\n",
       "      <td>CNN</td>\n",
       "      <td>http://example1.com</td>\n",
       "      <td>Title for article 1</td>\n",
       "      <td>Abortion is okay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87654321</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-12-15</td>\n",
       "      <td>US</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>http://example2.com</td>\n",
       "      <td>Title for article 2</td>\n",
       "      <td>Abortion is not okay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23456789</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-03-22</td>\n",
       "      <td>US</td>\n",
       "      <td>CNN</td>\n",
       "      <td>http://example3.com</td>\n",
       "      <td>Title for article 3</td>\n",
       "      <td>Abortion is good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>98765432</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-05-10</td>\n",
       "      <td>US</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>http://example4.com</td>\n",
       "      <td>Title for article 4</td>\n",
       "      <td>Abortion is bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34567890</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-10-05</td>\n",
       "      <td>US</td>\n",
       "      <td>CNN</td>\n",
       "      <td>http://example5.com</td>\n",
       "      <td>Title for article 5</td>\n",
       "      <td>Abortion is something I am for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>76543210</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-12-18</td>\n",
       "      <td>US</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>http://example6.com</td>\n",
       "      <td>Title for article 6</td>\n",
       "      <td>Abortion is something I am against.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>45678901</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-01-29</td>\n",
       "      <td>US</td>\n",
       "      <td>CNN</td>\n",
       "      <td>http://example7.com</td>\n",
       "      <td>Title for article 7</td>\n",
       "      <td>Abortion is cool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10987654</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-05-12</td>\n",
       "      <td>US</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>http://example8.com</td>\n",
       "      <td>Title for article 8</td>\n",
       "      <td>Abortion is uncool</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>56789012</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-09-25</td>\n",
       "      <td>US</td>\n",
       "      <td>CNN</td>\n",
       "      <td>http://example9.com</td>\n",
       "      <td>Title for article 9</td>\n",
       "      <td>Abortion is definitely nice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>21098765</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-12-14</td>\n",
       "      <td>US</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>http://example10.com</td>\n",
       "      <td>Title for article 10</td>\n",
       "      <td>Abortion is definitely not nice.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>67890123</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>US</td>\n",
       "      <td>CNN</td>\n",
       "      <td>http://example11.com</td>\n",
       "      <td>Title for article 11</td>\n",
       "      <td>Abortion is the best</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>32109876</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-04-19</td>\n",
       "      <td>US</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>http://example12.com</td>\n",
       "      <td>Title for article 12</td>\n",
       "      <td>Abortion is the worst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>78901234</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-07-05</td>\n",
       "      <td>US</td>\n",
       "      <td>CNN</td>\n",
       "      <td>http://example13.com</td>\n",
       "      <td>Title for article 13</td>\n",
       "      <td>I love Abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>43210987</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-10-08</td>\n",
       "      <td>US</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>http://example14.com</td>\n",
       "      <td>Title for article 14</td>\n",
       "      <td>I hate Abortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>89012345</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-12-13</td>\n",
       "      <td>US</td>\n",
       "      <td>CNN</td>\n",
       "      <td>http://example15.com</td>\n",
       "      <td>Title for article 15</td>\n",
       "      <td>Abortion is best thing ever</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>54321098</td>\n",
       "      <td>5</td>\n",
       "      <td>2024-02-21</td>\n",
       "      <td>US</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>http://example16.com</td>\n",
       "      <td>Title for article 16</td>\n",
       "      <td>Abortion is murder against innocent babies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>90123456</td>\n",
       "      <td>5</td>\n",
       "      <td>2024-05-07</td>\n",
       "      <td>US</td>\n",
       "      <td>CNN</td>\n",
       "      <td>http://example17.com</td>\n",
       "      <td>Title for article 17</td>\n",
       "      <td>Abortion is a cornerstone of women's rights.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>65432109</td>\n",
       "      <td>5</td>\n",
       "      <td>2024-08-25</td>\n",
       "      <td>US</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>http://example18.com</td>\n",
       "      <td>Title for article 18</td>\n",
       "      <td>Abortion should be banned in all states</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>11223344</td>\n",
       "      <td>5</td>\n",
       "      <td>2024-10-14</td>\n",
       "      <td>US</td>\n",
       "      <td>CNN</td>\n",
       "      <td>http://example19.com</td>\n",
       "      <td>Title for article 19</td>\n",
       "      <td>Abortion secures women's autonomy and freedom.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>44332211</td>\n",
       "      <td>5</td>\n",
       "      <td>2024-11-05</td>\n",
       "      <td>US</td>\n",
       "      <td>Fox News</td>\n",
       "      <td>http://example20.com</td>\n",
       "      <td>Title for article 20</td>\n",
       "      <td>Abortion is unjust and takes away innocent lives.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      textID  words        date country    source                   url  \\\n",
       "0   12345678      5  2020-11-03      US       CNN   http://example1.com   \n",
       "1   87654321      5  2020-12-15      US  Fox News   http://example2.com   \n",
       "2   23456789      5  2021-03-22      US       CNN   http://example3.com   \n",
       "3   98765432      5  2021-05-10      US  Fox News   http://example4.com   \n",
       "4   34567890      5  2021-10-05      US       CNN   http://example5.com   \n",
       "5   76543210      5  2021-12-18      US  Fox News   http://example6.com   \n",
       "6   45678901      5  2022-01-29      US       CNN   http://example7.com   \n",
       "7   10987654      5  2022-05-12      US  Fox News   http://example8.com   \n",
       "8   56789012      5  2022-09-25      US       CNN   http://example9.com   \n",
       "9   21098765      5  2022-12-14      US  Fox News  http://example10.com   \n",
       "10  67890123      5  2023-01-01      US       CNN  http://example11.com   \n",
       "11  32109876      5  2023-04-19      US  Fox News  http://example12.com   \n",
       "12  78901234      5  2023-07-05      US       CNN  http://example13.com   \n",
       "13  43210987      5  2023-10-08      US  Fox News  http://example14.com   \n",
       "14  89012345      5  2023-12-13      US       CNN  http://example15.com   \n",
       "15  54321098      5  2024-02-21      US  Fox News  http://example16.com   \n",
       "16  90123456      5  2024-05-07      US       CNN  http://example17.com   \n",
       "17  65432109      5  2024-08-25      US  Fox News  http://example18.com   \n",
       "18  11223344      5  2024-10-14      US       CNN  http://example19.com   \n",
       "19  44332211      5  2024-11-05      US  Fox News  http://example20.com   \n",
       "\n",
       "                   title                                               body  \n",
       "0    Title for article 1                                   Abortion is okay  \n",
       "1    Title for article 2                               Abortion is not okay  \n",
       "2    Title for article 3                                   Abortion is good  \n",
       "3    Title for article 4                                    Abortion is bad  \n",
       "4    Title for article 5                     Abortion is something I am for  \n",
       "5    Title for article 6                Abortion is something I am against.  \n",
       "6    Title for article 7                                   Abortion is cool  \n",
       "7    Title for article 8                                 Abortion is uncool  \n",
       "8    Title for article 9                        Abortion is definitely nice  \n",
       "9   Title for article 10                   Abortion is definitely not nice.  \n",
       "10  Title for article 11                               Abortion is the best  \n",
       "11  Title for article 12                              Abortion is the worst  \n",
       "12  Title for article 13                                    I love Abortion  \n",
       "13  Title for article 14                                    I hate Abortion  \n",
       "14  Title for article 15                        Abortion is best thing ever  \n",
       "15  Title for article 16         Abortion is murder against innocent babies  \n",
       "16  Title for article 17       Abortion is a cornerstone of women's rights.  \n",
       "17  Title for article 18            Abortion should be banned in all states  \n",
       "18  Title for article 19     Abortion secures women's autonomy and freedom.  \n",
       "19  Title for article 20  Abortion is unjust and takes away innocent lives.  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define the data for each column\n",
    "data = {\n",
    "    \"textID\": [12345678, 87654321, 23456789, 98765432, 34567890, \n",
    "               76543210, 45678901, 10987654, 56789012, 21098765,\n",
    "               67890123, 32109876, 78901234, 43210987, 89012345,\n",
    "               54321098, 90123456, 65432109, 11223344, 44332211],\n",
    "    \"words\": [5] * 20,\n",
    "    \"date\": [\n",
    "        \"2020-11-03\", \"2020-12-15\", \"2021-03-22\", \"2021-05-10\", \n",
    "        \"2021-10-05\", \"2021-12-18\", \"2022-01-29\", \"2022-05-12\",\n",
    "        \"2022-09-25\", \"2022-12-14\", \"2023-01-01\", \"2023-04-19\",\n",
    "        \"2023-07-05\", \"2023-10-08\", \"2023-12-13\", \"2024-02-21\", \n",
    "        \"2024-05-07\", \"2024-08-25\", \"2024-10-14\", \"2024-11-05\"\n",
    "    ],\n",
    "    \"country\": [\"US\"] * 20,\n",
    "    \"source\": [\"CNN\", \"Fox News\"] * 10,\n",
    "    \"url\": [f\"http://example{num}.com\" for num in range(1, 21)],\n",
    "    \"title\": [f\"Title for article {i}\" for i in range(1, 21)],\n",
    "    \"body\": [\n",
    "        \"Abortion is okay\",\n",
    "        \"Abortion is not okay\",\n",
    "        \"Abortion is good\",\n",
    "        \"Abortion is bad\",\n",
    "        \"Abortion is something I am for\",\n",
    "        \"Abortion is something I am against.\",\n",
    "        \"Abortion is cool\",\n",
    "        \"Abortion is uncool\",\n",
    "        \"Abortion is definitely nice\",\n",
    "        \"Abortion is definitely not nice.\",\n",
    "        \"Abortion is the best\",\n",
    "        \"Abortion is the worst\",\n",
    "        \"I love Abortion\",\n",
    "        \"I hate Abortion\",\n",
    "        \"Abortion is best thing ever\",\n",
    "        \"Abortion is murder against innocent babies\",\n",
    "        \"Abortion is a cornerstone of women's rights.\",\n",
    "        \"Abortion should be banned in all states\",\n",
    "        \"Abortion secures women's autonomy and freedom.\",\n",
    "        \"Abortion is unjust and takes away innocent lives.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create the DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "000a5fa9-b36d-4c96-b12a-cf66f69c6d94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>semantic_polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>0.036512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021</td>\n",
       "      <td>0.053813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022</td>\n",
       "      <td>0.074041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023</td>\n",
       "      <td>0.374675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024</td>\n",
       "      <td>0.044064</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  semantic_polarity\n",
       "0  2020           0.036512\n",
       "1  2021           0.053813\n",
       "2  2022           0.074041\n",
       "3  2023           0.374675\n",
       "4  2024           0.044064"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to get contextual embedding for a specific keyword in an article\n",
    "def get_contextual_embedding(text, keyword):\n",
    "    tokens = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        output = model(**tokens)\n",
    "    keyword_id = tokenizer.encode(keyword, add_special_tokens=False)[0]\n",
    "    keyword_index = (tokens.input_ids == keyword_id).nonzero(as_tuple=True)[1]\n",
    "    \n",
    "    if len(keyword_index) > 0:\n",
    "        return output.last_hidden_state[0, keyword_index, :].mean(dim=0).numpy()\n",
    "    else:\n",
    "        return None  # Return None if keyword isn't found\n",
    "\n",
    "# Function to compute semantic polarity\n",
    "def compute_semantic_polarity(cnn_embeddings, fox_embeddings):\n",
    "    total_distance = 0\n",
    "    count = 0\n",
    "    for cnn_emb in cnn_embeddings:\n",
    "        for fox_emb in fox_embeddings:\n",
    "            distance = 1 - cosine_similarity(cnn_emb.reshape(1, -1), fox_emb.reshape(1, -1))[0][0]\n",
    "            total_distance += distance\n",
    "            count += 1\n",
    "    return total_distance / count if count > 0 else 0\n",
    "\n",
    "# Group articles by year\n",
    "df['year'] = pd.to_datetime(df['date']).dt.year\n",
    "results = []\n",
    "\n",
    "for year, group in df.groupby('year'):\n",
    "    cnn_group = group[group['source'] == 'CNN']\n",
    "    fox_group = group[group['source'] == 'Fox News']\n",
    "    \n",
    "    # Extract embeddings for each article mentioning 'abortion'\n",
    "    cnn_embeddings = [get_contextual_embedding(body, 'abortion') for body in cnn_group['body'] if get_contextual_embedding(body, 'abortion') is not None]\n",
    "    fox_embeddings = [get_contextual_embedding(body, 'abortion') for body in fox_group['body'] if get_contextual_embedding(body, 'abortion') is not None]\n",
    "    \n",
    "    # Calculate semantic polarity for this year\n",
    "    sp_score = compute_semantic_polarity(cnn_embeddings, fox_embeddings)\n",
    "    results.append({'year': year, 'semantic_polarity': sp_score})\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "sp_df = pd.DataFrame(results)\n",
    "\n",
    "# Display results\n",
    "#import ace_tools as tools; tools.display_dataframe_to_user(name=\"Semantic Polarity Over Time\", dataframe=sp_df)\n",
    "sp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "385b92e1-34b4-48c3-869e-e7d5914c7dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))  # Set the plot size\n",
    "plt.plot(sp_df['year'], sp_df['semantic_polarity'], marker='o', linestyle='-', linewidth=2)\n",
    "\n",
    "# Set the title and labels\n",
    "plt.title('Semantic Polarity Over Time (CNN vs. Fox News on \"Abortion\")', fontsize=14)\n",
    "plt.xlabel('Year', fontsize=12)\n",
    "plt.ylabel('Semantic Polarity (SP)', fontsize=12)\n",
    "\n",
    "# Add grid and customize the x-ticks to show all years\n",
    "plt.grid(True)\n",
    "plt.xticks(sp_df['year'])\n",
    "\n",
    "plt.tight_layout()  # Adjust layout for better spacing\n",
    "plt.show()  # Display the plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd692a1-c03d-45ca-85e0-60718f800c2a",
   "metadata": {},
   "source": [
    "### I don't know if I like python's visualizations. So I'll save the semantic polarity scores as csv and visualize in r."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bb9d9c82-7216-47d6-990b-50421d9afee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path where you want to save the CSV\n",
    "output_file_path = \"/work/Bachelor/results_for_plots/sp_df.csv\"\n",
    "\n",
    "# Save the filtered DataFrame as a CSV file\n",
    "sp_df.to_csv(output_file_path, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525e6515-635c-4554-a295-648d351df5c0",
   "metadata": {},
   "source": [
    "# Thoughts:\n",
    "\n",
    "## - Very small polarization scores...\n",
    "## - is BERT good (bert-base-uncased)? Or would a SentenceTransformer be better??\n",
    "## - Which keywords should I check for? All from the query list, or just abortion, or just the ones that are present in both news outlets (find out from topic modeling on the individual news sources) --> when you've figured it out, potentially modify code to be able to take more keywords, or duplicate code and use for the different keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31387402-a3ce-4e3b-ba63-0f1697997802",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
